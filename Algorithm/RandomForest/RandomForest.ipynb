{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "# 파이썬 환경 구축 후 라이브러리 버전 맞춰 설치\n",
    "packages_to_install = [\n",
    "    \"transformers==4.30.2\",\n",
    "    \"torch==2.1.0\",\n",
    "    \"soynlp==0.0.493\",\n",
    "    \"requests==2.31.0\",\n",
    "    \"tensorflow==2.10.0\",\n",
    "    \"accelerate==0.20.1\",\n",
    "    \"kss==4.5.4\",\n",
    "    \"matplotlib==3.7.3\",\n",
    "    \"wordcloud==1.9.2\",\n",
    "    \"JPype1==1.4.1\",\n",
    "    \"rhinoMorph==4.0.1.12\",\n",
    "    \"kiwipiepy==0.16.1\",\n",
    "    \"Konlpy==0.6.0\",\n",
    "    \"nltk==3.8.1\",\n",
    "    \"seaborn==0.13.0\"\n",
    "]\n",
    "\n",
    "for package in packages_to_install:\n",
    "    os.system(f\"pip install {package}\")\n",
    "\n",
    "# pip 업그레이드\n",
    "os.system(\"python -m pip install --upgrade pip\")\n",
    "\n",
    "# 파이썬 라이브러리 버전 전체 확인\n",
    "os.system(\"pip freeze\")\n",
    "\n",
    "# 파이썬 라이브러리 버전 하나씩 확인\n",
    "packages_to_show = [\n",
    "    \"transformers\",\n",
    "    \"torch\",\n",
    "    \"soynlp\",\n",
    "    \"requests\",\n",
    "    \"tensorflow\",\n",
    "    \"accelerate\",\n",
    "    \"kss\",\n",
    "    \"matplotlib\",\n",
    "    \"wordcloud\",\n",
    "    \"JPype1\",\n",
    "    \"rhinoMorph\",\n",
    "    \"kiwipiepy\",\n",
    "    \"Konlpy\",\n",
    "    \"nltk\",\n",
    "    \"seaborn\"\n",
    "]\n",
    "\n",
    "for package in packages_to_show:\n",
    "    os.system(f\"pip show {package}\")\n",
    "\n",
    "\n",
    "# git에서 라이브러리 복제\n",
    "os.system(\"git clone https://github.com/ZIZUN/korean-malicious-comments-dataset.git\")\n",
    "os.system(\"bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\")\n",
    "\n",
    "subprocess.call(\"pip install git+https://github.com/haven-jeon/PyKoSpacing.git\", shell=True)\n",
    "print(\"라이브러리 설치가 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "device=torch.device('cuda:0'if torch.cuda.is_available()else 'cpu')\n",
    "print(\"device =\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\dataset\\sample_data(100).xlsx\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_idx = df[df.label.isnull()].index                             # 해당 index에 null 값 확인\n",
    "df.loc[null_idx, \"Sentence\"]                                       # null 값이 존재한 인덱스의 content 값 불러오기\n",
    "\n",
    "# lable은 content의 가장 끝 문장열로 설정\n",
    "df.loc[null_idx, \"label\"] = df.loc[null_idx, \"Sentence\"].apply(lambda x: x[-1])\n",
    "\n",
    "# content는 \"\\t\" 앞부분까지의 문자열로 설정\n",
    "df.loc[null_idx, \"Sentence\"] = df.loc[null_idx, \"Sentence\"].apply(lambda x: x[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Morphological_Analyzer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kiwipiepy import Kiwi\n",
    "from kiwi import *\n",
    "\n",
    "kiwi_pre_train = df.sample(frac=0.8, random_state=42)                     # train(80%), test(20%) 셋 구분 \n",
    "kiwi_pre_test = df.drop(kiwi_pre_train.index)                             # 랜덤으로 샘플링(랜덤으로 숫자 배치)\n",
    "\n",
    "# 데이터셋 갯수 확인\n",
    "print('중복 제거 전 학습 데이터셋 : {}'.format(len(kiwi_pre_train)))\n",
    "print('중복 제거 전 테스트 데이터셋 : {}'.format(len(kiwi_pre_test)))\n",
    "\n",
    "# 중복 데이터 제거\n",
    "kiwi_pre_train.drop_duplicates(subset=[\"Sentence\"], inplace=True)\n",
    "kiwi_pre_test.drop_duplicates(subset=[\"Sentence\"], inplace=True)\n",
    "\n",
    "# 형태소 분석 적용\n",
    "train_morp = list(kiwi.tokenize(kiwi_pre_train['Sentence'].tolist(), normalize_coda=True))\n",
    "test_morp = list(kiwi.tokenize(kiwi_pre_test['Sentence'].tolist(), normalize_coda=True))\n",
    "\n",
    "train_data = [train_morp, kiwi_pre_train['label']]\n",
    "test_data = [test_morp, kiwi_pre_test['label']]\n",
    "\n",
    "\n",
    "# 데이터셋 갯수 확인\n",
    "print('중복 제거 후 학습 데이터셋 : {}'.format(len(train_data[0])))\n",
    "print('중복 제거 후 테스트 데이터셋 : {}'.format(len(test_data[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장에서 최대 토큰 수 계산\n",
    "max_tokens = max(len(sentence) for sentence in train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 생성\n",
    "train_df = pd.DataFrame(index=range(len(train_data[0])), columns=range(max_tokens + 1))\n",
    "\n",
    "# 각 문장에 대해 반복하면서 DataFrame 생성\n",
    "for i, sentence in enumerate(train_data[0]):\n",
    "    # DataFrame에 토큰 형태 추가\n",
    "    for j, token in enumerate(sentence):\n",
    "        train_df.loc[i, j] = token.form\n",
    "\n",
    "    # 마지막 열에 'label' 값 추가\n",
    "    train_df.loc[i, max_tokens] = train_data[1].iloc[i]\n",
    "\n",
    "# NaN 값을 빈 문자열로 대체\n",
    "train_df = train_df.fillna('')\n",
    "\n",
    "# 결과적인 DataFrame 출력\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DataFrame 생성\n",
    "test_df = pd.DataFrame(index=range(len(test_data[0])), columns=range(max_tokens + 1))  # Add one more column for 'label'\n",
    "\n",
    "# 각 문장에 대해 반복하면서 DataFrame 생성# 각 문장에서 최대 토큰 수 계산\n",
    "# max_tokens = max(len(sentence) for sentence in test_data[0])\n",
    "for i, sentence in enumerate(test_data[0]):\n",
    "    # DataFrame에 토큰 형태 추가\n",
    "    for j, token in enumerate(sentence):\n",
    "        test_df.loc[i, j] = token.form\n",
    "\n",
    "    # 마지막 열에 'label' 값 추가\n",
    "    test_df.loc[i, max_tokens] = test_data[1].iloc[i]  # Use .iloc[i] to access the value at index i\n",
    "\n",
    "# NaN 값을 빈 문자열로 대체\n",
    "test_df = test_df.fillna('')\n",
    "\n",
    "# 결과적인 DataFrame 출력\n",
    "print(test_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "# 불용어(stopwords) 리스트를 직접 만들어 사용하거나, 외부에서 가져와 사용합니다.\n",
    "stop_words = set(['는', '은', '이', '가', '을', '를','그리고','그래서','또한','그러하니','그러나','그리하여','그리하여금','그러한','그러므로',''])  # 사용자 정의 불용어 리스트 예시\n",
    "\n",
    "# 불용어(stopwords) 리스트에 사용자 정의 불용어를 추가합니다.\n",
    "# stop_words = set(stopwords.words('english') + custom_stopwords)\n",
    "\n",
    "for column_index in train_df.columns:\n",
    "    for index, value in enumerate(train_df[column_index]):\n",
    "        if isinstance(value, str):  # 문자열인 경우에만 토큰화 수행\n",
    "            word_tokens = word_tokenize(value)\n",
    "            # 불용어 제거\n",
    "            train_df[column_index][index] = ' '.join([word for word in word_tokens if not word in stop_words])\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "train_df['merged_sentences'] = train_df.apply(lambda row: ' '.join([str(token) for token in row if token is not None]), axis=1)\n",
    "print(train_df['merged_sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_index in test_df.columns:\n",
    "    for index, value in enumerate(test_df[column_index]):\n",
    "        if isinstance(value, str):  # 문자열인 경우에만 토큰화 수행\n",
    "            word_tokens = word_tokenize(value)\n",
    "            # 불용어 제거\n",
    "            test_df[column_index][index] = ' '.join([word for word in word_tokens if not word in stop_words])\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "test_df['merged_sentences'] = test_df.apply(lambda row: ' '.join([str(token) for token in row if token is not None]), axis=1)\n",
    "print(test_df['merged_sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_df[128].values\n",
    "test_label = test_df[128].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 텍스트를 TF-IDF 벡터로 변환합니다.\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df['merged_sentences'])\n",
    "X_test = vectorizer.transform(test_df['merged_sentences'])  # transform만 사용\n",
    "\n",
    "# 랜덤 포레스트 모델을 생성하고 학습합니다.\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, train_label)\n",
    "\n",
    "# 테스트 데이터에 대한 예측을 수행합니다.\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 정확도를 출력합니다.\n",
    "accuracy = accuracy_score(test_label, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_scores( test_label, y_pred, pred_proba=None):\n",
    "    # 필요한 모듈 임포트\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, \\\n",
    "        roc_auc_score\n",
    "    \n",
    "    # 오차 행렬 계산\n",
    "    cm = confusion_matrix(test_label, y_pred)\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    \n",
    "    # 다양한 성능 지표 출력\n",
    "    print('오차행렬 \\n', cm)\n",
    "    print('Accuracy_score(정확도) :', accuracy_score(test_label, y_pred))\n",
    "    print('Precision(정밀도) : ', precision_score(test_label, y_pred))\n",
    "    print('Recall(재현율) :', recall_score(test_label, y_pred))\n",
    "    \n",
    "    # TNR은 True Negative Rate로, 실제 0인 것 중에서 모델이 정확하게 예측한 비율입니다.\n",
    "    print('TNR(0을 맞춘 비율) :', TN / (TN + FP))\n",
    "    \n",
    "    # F1 score 계산\n",
    "    print('F1 score :', f1_score(test_label, y_pred))\n",
    "    \n",
    "    # 예측 확률이 주어진 경우에만 Roc Auc score 출력\n",
    "    if pred_proba is not None:\n",
    "        print('Roc Auc score :', roc_auc_score(test_label, pred_proba))\n",
    "\n",
    "        # 혼동 행렬 그리기\n",
    "    cm = confusion_matrix(test_label, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print_scores(test_label,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: curse, 1: non_curse\n",
    "def sentence_predict(sent):\n",
    "    sentence=True\n",
    "    new_data_transformed = vectorizer.transform([sent])\n",
    "    prediction = rf_model.predict(new_data_transformed)\n",
    "    \n",
    "    if prediction == 0:\n",
    "        sentence = True #정상어\n",
    "\n",
    "    elif prediction == 1:\n",
    "        sentence = False #비속어\n",
    "    return sentence, sent\n",
    "\n",
    "sentence_predict(\"화이팅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def badword_find(sent):\n",
    "    result = sent\n",
    "    badword_df = pd.read_excel(r'C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\dataset\\word_list.xlsx')\n",
    "    \n",
    "    found_bad_word = False  # 입력 문장에 단어가 발견되었는지를 나타내는 플래그\n",
    "    for idx, row in badword_df.iterrows():\n",
    "        if row[\"WORD\"] in sent:\n",
    "            # 'WORD'가 입력 문장에 포함된 경우\n",
    "            new_word = row[\"대체어\"]\n",
    "            if not pd.isnull(new_word):\n",
    "                result = result.replace(row[\"WORD\"], new_word)\n",
    "                found_bad_word = True\n",
    "            else:\n",
    "                result = result.replace(row[\"WORD\"], \"*\" * len(row[\"WORD\"]))\n",
    "                found_bad_word = True\n",
    "    \n",
    "    if not found_bad_word:\n",
    "        # result = \"@\" * len(input_sentence)\n",
    "        result = \"혐오 표현입니다.\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_pre(sent):\n",
    "    sentence = sentence_predict(sent)\n",
    "    if sentence[0] == True:\n",
    "        return sent\n",
    "    elif sentence[0] == False:\n",
    "        return badword_find(sent)\n",
    "    \n",
    "def speak(sent):\n",
    "    speak_pre(sent)\n",
    "    sentence = sentence_predict(sent)\n",
    "    if sentence[0] == True:\n",
    "        return sent\n",
    "    elif sentence[0] == False:\n",
    "        return badword_find(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pykospacing import Spacing\n",
    "spacing = Spacing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 제거\n",
    "def cleanse(text):\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ|a-zA-Z0-9]','', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/time_distributed_1/dense_1/MatMul' defined at (most recent call last):\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\GJAISCHOOL\\AppData\\Local\\Temp\\ipykernel_1504\\1263202524.py\", line 12, in <module>\n      clean_and_repeat_normalize(\"아버지가방에들어가신다\")\n    File \"C:\\Users\\GJAISCHOOL\\AppData\\Local\\Temp\\ipykernel_1504\\1263202524.py\", line 8, in clean_and_repeat_normalize\n      normalized_text = spacing(input_data)                                     # 띄어쓰기 보정\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\pykospacing\\kospacing.py\", line 178, in __call__\n      spaced_sent = self.get_spaced_sent(filtered_sent, deleted_str_list, deleted_idx_list, orig_sent, post_process)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\pykospacing\\kospacing.py\", line 70, in get_spaced_sent\n      results = self._model.predict(mat_in, verbose=0)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\time_distributed.py\", line 221, in call\n      y = self.layer(inputs, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 221, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'model_1/time_distributed_1/dense_1/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_1/time_distributed_1/dense_1/MatMul}}]] [Op:__inference_predict_function_1338]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\RandomForest\\RandomForest.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/GJAISCHOOL/Desktop/X_filter/Algorithm/RandomForest/RandomForest.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     normalized_text \u001b[39m=\u001b[39m spacing(input_data)                                     \u001b[39m# 띄어쓰기 보정 \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GJAISCHOOL/Desktop/X_filter/Algorithm/RandomForest/RandomForest.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m normalized_text\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/GJAISCHOOL/Desktop/X_filter/Algorithm/RandomForest/RandomForest.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m clean_and_repeat_normalize(\u001b[39m\"\u001b[39;49m\u001b[39m아버지가방에들어가신다\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\RandomForest\\RandomForest.ipynb Cell 21\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/GJAISCHOOL/Desktop/X_filter/Algorithm/RandomForest/RandomForest.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m normalized_text \u001b[39m=\u001b[39m repeat_normalize(cleansed_text, num_repeats\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)          \u001b[39m# 중복문자 제거\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/GJAISCHOOL/Desktop/X_filter/Algorithm/RandomForest/RandomForest.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m input_data \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, normalized_text)                           \u001b[39m#  제거\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/GJAISCHOOL/Desktop/X_filter/Algorithm/RandomForest/RandomForest.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m normalized_text \u001b[39m=\u001b[39m spacing(input_data)                                     \u001b[39m# 띄어쓰기 보정 \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GJAISCHOOL/Desktop/X_filter/Algorithm/RandomForest/RandomForest.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m normalized_text\n",
      "File \u001b[1;32mc:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\pykospacing\\kospacing.py:178\u001b[0m, in \u001b[0;36mSpacing.__call__\u001b[1;34m(self, sent, ignore, ignore_pattern)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[39m# if ignore == 'post', set post_process to True\u001b[39;00m\n\u001b[0;32m    177\u001b[0m     post_process \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m ignore \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     spaced_sent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_spaced_sent(filtered_sent, deleted_str_list, deleted_idx_list, orig_sent, post_process)\n\u001b[0;32m    179\u001b[0m     result_sent\u001b[39m.\u001b[39mappend(spaced_sent)\n\u001b[0;32m    180\u001b[0m spaced_sent \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(result_sent)\n",
      "File \u001b[1;32mc:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\pykospacing\\kospacing.py:70\u001b[0m, in \u001b[0;36mSpacing.get_spaced_sent\u001b[1;34m(self, raw_sent, deleted_str_list, deleted_idx_list, orig_sent, post_process)\u001b[0m\n\u001b[0;32m     66\u001b[0m sents_in \u001b[39m=\u001b[39m [raw_sent_, ]\n\u001b[0;32m     67\u001b[0m mat_in \u001b[39m=\u001b[39m encoding_and_padding(\n\u001b[0;32m     68\u001b[0m     word2idx_dic\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_w2idx, sequences\u001b[39m=\u001b[39msents_in, maxlen\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m,\n\u001b[0;32m     69\u001b[0m     padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m, truncating\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mpredict(mat_in, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     71\u001b[0m mat_set \u001b[39m=\u001b[39m results[\u001b[39m0\u001b[39m,]\n\u001b[0;32m     72\u001b[0m preds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m mat_set[:\u001b[39mlen\u001b[39m(raw_sent_)]])\n",
      "File \u001b[1;32mc:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/time_distributed_1/dense_1/MatMul' defined at (most recent call last):\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\GJAISCHOOL\\AppData\\Local\\Temp\\ipykernel_1504\\1263202524.py\", line 12, in <module>\n      clean_and_repeat_normalize(\"아버지가방에들어가신다\")\n    File \"C:\\Users\\GJAISCHOOL\\AppData\\Local\\Temp\\ipykernel_1504\\1263202524.py\", line 8, in clean_and_repeat_normalize\n      normalized_text = spacing(input_data)                                     # 띄어쓰기 보정\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\pykospacing\\kospacing.py\", line 178, in __call__\n      spaced_sent = self.get_spaced_sent(filtered_sent, deleted_str_list, deleted_idx_list, orig_sent, post_process)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\pykospacing\\kospacing.py\", line 70, in get_spaced_sent\n      results = self._model.predict(mat_in, verbose=0)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\time_distributed.py\", line 221, in call\n      y = self.layer(inputs, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 221, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'model_1/time_distributed_1/dense_1/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node model_1/time_distributed_1/dense_1/MatMul}}]] [Op:__inference_predict_function_1338]"
     ]
    }
   ],
   "source": [
    "from pykospacing import Spacing\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "spacing = Spacing()\n",
    "def clean_and_repeat_normalize(text):\n",
    "    cleansed_text = cleanse(text)                                             # 특수문자 제거\n",
    "    normalized_text = repeat_normalize(cleansed_text, num_repeats=2)          # 중복문자 제거\n",
    "    input_data = re.sub(r'\\d', '', normalized_text)                           #  제거\n",
    "    normalized_text = spacing(input_data)                                     # 띄어쓰기 보정 \n",
    "\n",
    "    return normalized_text\n",
    "\n",
    "clean_and_repeat_normalize(\"아버지가방에들어가신다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kss\n",
    "def final_output():\n",
    "    input_text = clean_and_repeat_normalize(input())\n",
    "    sentences = kss.split_sentences(input_text)\n",
    "\n",
    "    sentences_list = []\n",
    "    for sentence in sentences:\n",
    "        speak(sentence)\n",
    "        sentences_list.append(sentence) \n",
    "\n",
    "    long_test = ' '.join(sentences_list)\n",
    "    print(long_test)\n",
    "    return long_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kcelec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
