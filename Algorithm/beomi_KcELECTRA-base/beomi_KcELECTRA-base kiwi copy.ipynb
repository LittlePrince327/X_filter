{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17563410680225028472\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2254123828\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14876018254815013310\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run KcELECTRA-base.version.py\n",
    "# !pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# GPU 설정\n",
    "# 없을 시 CPU\n",
    "# CPU로 뜨지만, GPU 잘만 돌아감\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좌배 까는건 ㅇㅂ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>세탁이라고 봐도 된다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>애새끼가 초딩도 아니고 ㅋㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Sentence  label\n",
       "0                                    좌배 까는건 ㅇㅂ      1\n",
       "1                 집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ      0\n",
       "2  개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아      1\n",
       "3                                  세탁이라고 봐도 된다      0\n",
       "4                            애새끼가 초딩도 아니고 ㅋㅋㅋㅋ      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 엑셀 파일에서 데이터프레임 읽기\n",
    "df = pd.read_excel(r\"C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\dataset\\sample_data(100).xlsx\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_idx = df[df.label.isnull()].index                             # 해당 index에 null 값 확인\n",
    "df.loc[null_idx, \"Sentence\"]                                       # null 값이 존재한 인덱스의 content 값 불러오기\n",
    "\n",
    "# lable은 content의 가장 끝 문장열로 설정\n",
    "df.loc[null_idx, \"label\"] = df.loc[null_idx, \"Sentence\"].apply(lambda x: x[-1])\n",
    "\n",
    "# content는 \"\\t\" 앞부분까지의 문자열로 설정\n",
    "df.loc[null_idx, \"Sentence\"] = df.loc[null_idx, \"Sentence\"].apply(lambda x: x[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 전 학습 데이터셋 : 80\n",
      "중복 제거 전 테스트 데이터셋 : 20\n",
      "중복 제거 후 학습 데이터셋 : 80\n",
      "중복 제거 후 테스트 데이터셋 : 20\n"
     ]
    }
   ],
   "source": [
    "train_data = df.sample(frac=0.8, random_state=42)                 # train(80%), test(20%) 셋 구분 \n",
    "test_data = df.drop(train_data.index)                             # 랜덤으로 샘플링(랜덤으로 숫자 배치)\n",
    "\n",
    "# 데이터셋 갯수 확인\n",
    "print('중복 제거 전 학습 데이터셋 : {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋 : {}'.format(len(test_data)))\n",
    "\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=[\"Sentence\"], inplace=True)\n",
    "test_data.drop_duplicates(subset=[\"Sentence\"], inplace=True)\n",
    "\n",
    "# 데이터셋 갯수 확인\n",
    "print('중복 제거 후 학습 데이터셋 : {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋 : {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification, TFElectraForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "# KcELECTRA 모델 및 토크나이저 로드\n",
    "model_name = \"beomi/KcELECTRA-base\"\n",
    "Kc_tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = Kc_tokenizer(\n",
    "    list(train_data['Sentence']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test_sentences = Kc_tokenizer(\n",
    "    list(test_data['Sentence']),\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=94, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "========================================================================================================================================================================================================\n",
      "['ĠìĥĪë¡ľ', 'ìĺ¤ë©´', 'Ġëĭ¤', 'Ġê·¸ëłĩê²Į', 'íķ¨', 'ĠìĹ´ìĭ¬íŀĪ', 'ĠíķĺëĬĶ', 'íĭ°', 'ë¥¼', 'ĠíĮįíĮį', 'ëĤ´ê³ł', 'ĠëŃĲ', 'Ġë°Ķê¾¸ê³ł', 'ĠëŃĲ', 'íķĺê¸°ë¡ľ', 'ĠíķĺìŀĲ', 'Ġìķķë°ķ', 'ìĿĦ', 'Ġì£¼', 'ìŀĸëĥĲ', 'Ġ10', 'ëħĦê°Ħ', 'ĠëĦĪë¬´', 'ĠíĥĢ', 'ìĦ±ìĹĲ', 'Ġìłĸ', 'ìĸ´', 'ìĤ´', 'ìķĺëįĺ', 'ê±°', 'ĠìķĦëĭĪëĥĲ', '?', 'ĠìľĦê¸°', 'ê°Ĳ', 'ìĹĨìĿ´', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "========================================================================================================================================================================================================\n",
      "[3718, 4283, 374, 1126, 861, 2348, 644, 1629, 395, 10556, 4093, 592, 10669, 592, 17097, 3165, 7944, 279, 597, 12529, 1362, 3416, 977, 1342, 7053, 9897, 319, 928, 11517, 303, 2084, 33, 7870, 785, 1478, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_sentences[0])        # 0번째 문장에 해당하는 객체\n",
    "print(\"=\"*200) \n",
    "print(tokenized_train_sentences[0].tokens) # 0번째 문장에 토큰의 목록\n",
    "print(\"=\"*200)\n",
    "print(tokenized_train_sentences[0].ids)    # 0번째 문장에 대한 고유 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurseDataset(torch.utils.data.Dataset):                                        # 학습을 위한 데이터셋 만들기     \n",
    "    def __init__(self, encoding, labels):                                            # pytorch에서 학습할 수 있게 데이터셋 생성\n",
    "        self.encodings = encoding                                                    # Feature Data / 'Sentence'\n",
    "        self.labels = labels                                                         # Target Data / 'Label'\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} # self.encodings 딕셔너리 내의 값 중에 val를 torch.tensor로 변환해 하여\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])                             # key: toch.tensor(val[ix])라는 item 딕셔너리 형성\n",
    "        return item                                                                 # 새로운 labels 키 값에 value torch.tensor(self.labels[idx]) 쌍을 생성\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)                                                     # self.labels 길이 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set에 대한 데이터셋을 각각 생성\n",
    "\n",
    "train_label = train_data['label'].values\n",
    "test_label = test_data['label'].values\n",
    "\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=3)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kc_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)   # 사전 학습된 모델 찾아오기\n",
    "Kc_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - 2 학습 파라미터 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './results',           # 학습결과 저장경로\n",
    "    num_train_epochs=10,                # 학습 epoch 설정\n",
    "    per_device_train_batch_size = 8,    # train batch_size 설정\n",
    "    per_device_eval_batch_size = 64,    # test batch_size 설정\n",
    "    logging_dir = './logs',             # 학습 log 저장경로\n",
    "    logging_steps=500,                  # 학습 log 기록 단위\n",
    "    save_total_limit = 2,               # 학습결과 저장 최대갯수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# 학습과정에서 사용할 평가지표를 위한 함수 설정\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  # 정밀도, 재현율, f1 구하기 \n",
    "  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "  # 정확도 구하기\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return{\n",
    "      'accuracy': acc,\n",
    "      'f1': f1,\n",
    "      'precision': precision,\n",
    "      'recall': recall\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 모듈을 사용해 모델의 학습을 컨트롤하은 trainer를 생성\n",
    "trainer = Trainer(\n",
    "    model = Kc_model,                       # 학습하고자하는 Transformers model\n",
    "    args=training_args,                  # 위에서 정의한 Trainging Arguments\n",
    "    train_dataset=train_dataset,         # 학습 데이터셋\n",
    "    eval_dataset=test_dataset,           # 평가 데이터셋\n",
    "    compute_metrics=compute_metrics,     # 평가지표\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.trainer.Trainer"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]C:\\Users\\GJAISCHOOL\\AppData\\Local\\Temp\\ipykernel_23256\\1869798269.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} # self.encodings 딕셔너리 내의 값 중에 val를 torch.tensor로 변환해 하여\n",
      "100%|██████████| 100/100 [05:28<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 328.72, 'train_samples_per_second': 2.434, 'train_steps_per_second': 0.304, 'train_loss': 0.3042463874816895, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.3042463874816895, metrics={'train_runtime': 328.72, 'train_samples_per_second': 2.434, 'train_steps_per_second': 0.304, 'train_loss': 0.3042463874816895, 'epoch': 10.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GJAISCHOOL\\AppData\\Local\\Temp\\ipykernel_23256\\1869798269.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} # self.encodings 딕셔너리 내의 값 중에 val를 torch.tensor로 변환해 하여\n",
      "100%|██████████| 1/1 [00:00<00:00, 83.20it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "results_matrix = trainer.predict(test_dataset)\n",
    "\n",
    "# Get the true labels and predicted logits\n",
    "true_labels = results_matrix.label_ids\n",
    "predicted_logits = results_matrix.predictions.argmax(-1)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_mat = confusion_matrix(true_labels, predicted_logits)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['P', 'N'], yticklabels=['T', 'F'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GJAISCHOOL\\AppData\\Local\\Temp\\ipykernel_23256\\1869798269.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} # self.encodings 딕셔너리 내의 값 중에 val를 torch.tensor로 변환해 하여\n",
      "100%|██████████| 1/1 [00:00<00:00, 38.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom__loss': 0.7523218989372253, 'custom__accuracy': 0.65, 'custom__f1': 0.6666666666666667, 'custom__precision': 0.5384615384615384, 'custom__recall': 0.875, 'custom__runtime': 0.946, 'custom__samples_per_second': 21.141, 'custom__steps_per_second': 1.057, 'epoch': 10.0}\n",
      "정확도 :  0.65\n",
      "정밀도 :  0.5384615384615384\n",
      "재현율 :  0.875\n",
      "F1 score :  0.6666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 평가를 수행하고 custom_ 접두사가 붙은 평가 지표를 출력\n",
    "results_score = trainer.evaluate(eval_dataset=test_dataset, metric_key_prefix='custom_')\n",
    "\n",
    "print(results_score)\n",
    "print(\"정확도 : \",results_score['custom__accuracy'])\n",
    "print(\"정밀도 : \",results_score['custom__precision'])\n",
    "print(\"재현율 : \",results_score['custom__recall'])\n",
    "print(\"F1 score : \",results_score['custom__f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, tensor([[2295,  640, 5170,   33]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0: curse, 1: non_curse\n",
    "def sentence_predict(sent):\n",
    "    # 평가모드로 변경\n",
    "    Kc_model.eval()\n",
    "\n",
    "    # 입력된 문장 토크나이징\n",
    "    tokenized_sent = Kc_tokenizer(\n",
    "        sent,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    # 모델이 위치한 GPU로 이동\n",
    "    # tokenized_sent.to(deivce)\n",
    "\n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = Kc_model(\n",
    "            input_ids=tokenized_sent[\"input_ids\"],\n",
    "            attention_mask=tokenized_sent[\"attention_mask\"],\n",
    "            token_type_ids=tokenized_sent[\"token_type_ids\"]\n",
    "        )\n",
    "\n",
    "    # 결과 return\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu()\n",
    "    result = logits.argmax(-1)\n",
    "    sentence = True\n",
    "    input_sentence = tokenized_sent[\"input_ids\"]\n",
    "    if result == 0:\n",
    "        sentence = True\n",
    "\n",
    "    elif result == 1:\n",
    "        sentence = False\n",
    "    return sentence, input_sentence\n",
    "\n",
    "\n",
    "sentence_predict(\"씨발 맞아?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, tensor([[2510]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_predict(\"화이팅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (2.9.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.24.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
      "\n",
      "Name: tensorflow\n",
      "Version: 2.9.3\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: pykospacing\n",
      "\n",
      "Epoch 1/20\n",
      "217/217 - 9s - loss: 5.7650 - accuracy: 0.1901 - 9s/epoch - 41ms/step\n",
      "Epoch 2/20\n",
      "217/217 - 6s - loss: 5.1609 - accuracy: 0.2022 - 6s/epoch - 27ms/step\n",
      "Epoch 3/20\n",
      "217/217 - 6s - loss: 4.7161 - accuracy: 0.2117 - 6s/epoch - 26ms/step\n",
      "Epoch 4/20\n",
      "217/217 - 6s - loss: 4.3593 - accuracy: 0.2320 - 6s/epoch - 27ms/step\n",
      "Epoch 5/20\n",
      "217/217 - 6s - loss: 4.0698 - accuracy: 0.2650 - 6s/epoch - 27ms/step\n",
      "Epoch 6/20\n",
      "217/217 - 6s - loss: 3.8293 - accuracy: 0.3030 - 6s/epoch - 26ms/step\n",
      "Epoch 7/20\n",
      "217/217 - 6s - loss: 3.6202 - accuracy: 0.3317 - 6s/epoch - 28ms/step\n",
      "Epoch 8/20\n",
      "217/217 - 6s - loss: 3.4327 - accuracy: 0.3558 - 6s/epoch - 27ms/step\n",
      "Epoch 9/20\n",
      "217/217 - 6s - loss: 3.2635 - accuracy: 0.3809 - 6s/epoch - 27ms/step\n",
      "Epoch 10/20\n",
      "217/217 - 6s - loss: 3.1129 - accuracy: 0.4217 - 6s/epoch - 26ms/step\n",
      "Epoch 11/20\n",
      "217/217 - 6s - loss: 2.9789 - accuracy: 0.4448 - 6s/epoch - 27ms/step\n",
      "Epoch 12/20\n",
      "217/217 - 6s - loss: 2.8581 - accuracy: 0.4600 - 6s/epoch - 27ms/step\n",
      "Epoch 13/20\n",
      "217/217 - 6s - loss: 2.7521 - accuracy: 0.4821 - 6s/epoch - 27ms/step\n",
      "Epoch 14/20\n",
      "217/217 - 6s - loss: 2.6576 - accuracy: 0.4971 - 6s/epoch - 27ms/step\n",
      "Epoch 15/20\n",
      "217/217 - 6s - loss: 2.5729 - accuracy: 0.5135 - 6s/epoch - 27ms/step\n",
      "Epoch 16/20\n",
      "217/217 - 6s - loss: 2.4967 - accuracy: 0.5253 - 6s/epoch - 26ms/step\n",
      "Epoch 17/20\n",
      "217/217 - 6s - loss: 2.4258 - accuracy: 0.5341 - 6s/epoch - 27ms/step\n",
      "Epoch 18/20\n",
      "217/217 - 6s - loss: 2.3630 - accuracy: 0.5458 - 6s/epoch - 27ms/step\n",
      "Epoch 19/20\n",
      "217/217 - 6s - loss: 2.3046 - accuracy: 0.5554 - 6s/epoch - 28ms/step\n",
      "Epoch 20/20\n",
      "217/217 - 6s - loss: 2.2517 - accuracy: 0.5665 - 6s/epoch - 27ms/step\n"
     ]
    }
   ],
   "source": [
    "# 'RNN_2' 모듈을 가져오기 위한 경로를 sys.path에 추가\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\RNN')\n",
    " \n",
    "# 'RNN' 모듈을 import\n",
    "from RNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혐오 표현입니다.\n"
     ]
    }
   ],
   "source": [
    "def badword_find(sent):\n",
    "    badword_df = pd.read_excel(r'C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\dataset\\word_list.xlsx')\n",
    "    found_bad_word = False  # 입력 문장에 단어가 발견되었는지를 나타내는 플래그\n",
    "    for idx, row in badword_df.iterrows():\n",
    "        if row[\"WORD\"] in sent:\n",
    "            # 'WORD'가 입력 문장에 포함된 경우\n",
    "            new_word = row[\"대체어\"]\n",
    "            if not pd.isnull(new_word):\n",
    "                RNN_result = sentence_generation(new_word, 2) + \" \"\n",
    "                sent = sent.replace(row[\"WORD\"], RNN_result)\n",
    "                found_bad_word = True\n",
    "            else:\n",
    "                sent = sent.replace(row[\"WORD\"], \"*\" * len(row[\"WORD\"]))\n",
    "                found_bad_word = True\n",
    "    \n",
    "    if not found_bad_word:\n",
    "        # result = \"@\" * len(input_sentence)\n",
    "        sent = \"혐오 표현입니다.\"\n",
    "    return sent\n",
    "\n",
    "# 테스트\n",
    "input_sentence = \"엄마가 죽었으면 좋겠어\"\n",
    "speak_result = badword_find(input_sentence)\n",
    "print(speak_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_pre(sent):\n",
    "    sentence = sentence_predict(sent)\n",
    "    if sentence[0] == True:\n",
    "        return sent\n",
    "    elif sentence[0] == False:\n",
    "        return badword_find(sent)\n",
    "    \n",
    "def speak(sent):\n",
    "    speak_pre(sent)\n",
    "    sentence = sentence_predict(sent)\n",
    "    if sentence == True:\n",
    "        return sent\n",
    "    elif sent == \"혐오 표현입니다.\":\n",
    "        return sent\n",
    "    elif sentence == False:\n",
    "        return badword_find(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import kss\n",
    "from pykospacing import Spacing\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "# 띄어쓰기 설정\n",
    "spacing = Spacing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 제거\n",
    "def cleanse(text):\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ|a-zA-Z0-9]','', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아버지가 방에 들어가신다'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_and_repeat_normalize(text):\n",
    "    cleansed_text = cleanse(text)                                             # 특수문자 제거\n",
    "    normalized_text = repeat_normalize(cleansed_text, num_repeats=2)          # 중복문자 제거\n",
    "    input_data = re.sub(r'\\d', '', normalized_text)                           # 숫자 제거\n",
    "    normalized_text = spacing(input_data)                                     # 띄어쓰기 보정 \n",
    "\n",
    "    return normalized_text\n",
    "\n",
    "clean_and_repeat_normalize(\"아버지가방에들어가신다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_output():\n",
    "    input_text = clean_and_repeat_normalize(input())\n",
    "    sentences = kss.split_sentences(input_text)\n",
    "\n",
    "    sentences_list = []\n",
    "    for sentence in sentences:\n",
    "        speak(sentence)\n",
    "        sentences_list.append(sentence) \n",
    "\n",
    "    long_test = ' '.join(sentences_list)\n",
    "    print(long_test)\n",
    "    return long_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "씨발병신 같네\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'씨발병신 같네'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 씨발 이게 맞아?\n",
    "final_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nv37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
