{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beomi/KcELECTRA-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17264573207228430519\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2256220980\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14818669193232887852\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Learning Device list Check \n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run KcELECTRA-base.version.py       # 필요한 라이브러리 설치\n",
    "# !pip freeze                          # 설치된 라이브러리 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# GPU 설정\n",
    "# 없을 시 CPU\n",
    "# CPU로 뜨지만, GPU 잘만 돌아감\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좌배 까는건 ㅇㅂ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>세탁이라고 봐도 된다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>애새끼가 초딩도 아니고 ㅋㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Sentence  label\n",
       "0                                    좌배 까는건 ㅇㅂ      1\n",
       "1                 집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ      0\n",
       "2  개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아      1\n",
       "3                                  세탁이라고 봐도 된다      0\n",
       "4                            애새끼가 초딩도 아니고 ㅋㅋㅋㅋ      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 엑셀 파일에서 데이터프레임 읽기\n",
    "df = pd.read_excel(r\"C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\dataset\\sample_data(100).xlsx\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_idx = df[df.label.isnull()].index                             # 해당 index에 null 값 확인\n",
    "df.loc[null_idx, \"Sentence\"]                                       # null 값이 존재한 인덱스의 content 값 불러오기\n",
    "\n",
    "# lable은 content의 가장 끝 문장열로 설정\n",
    "df.loc[null_idx, \"label\"] = df.loc[null_idx, \"Sentence\"].apply(lambda x: x[-1])\n",
    "\n",
    "# content는 \"\\t\" 앞부분까지의 문자열로 설정\n",
    "df.loc[null_idx, \"Sentence\"] = df.loc[null_idx, \"Sentence\"].apply(lambda x: x[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 전 학습 데이터셋 : 80\n",
      "중복 제거 전 테스트 데이터셋 : 20\n",
      "중복 제거 후 학습 데이터셋 : 80\n",
      "중복 제거 후 테스트 데이터셋 : 20\n"
     ]
    }
   ],
   "source": [
    "train_data = df.sample(frac=0.8, random_state=42)                 # train(80%), test(20%) 셋 구분 \n",
    "test_data = df.drop(train_data.index)                             # 랜덤으로 샘플링(랜덤으로 숫자 배치)\n",
    "\n",
    "# 데이터셋 갯수 확인\n",
    "print('중복 제거 전 학습 데이터셋 : {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋 : {}'.format(len(test_data)))\n",
    "\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=[\"Sentence\"], inplace=True)\n",
    "test_data.drop_duplicates(subset=[\"Sentence\"], inplace=True)\n",
    "\n",
    "# 데이터셋 갯수 확인\n",
    "print('중복 제거 후 학습 데이터셋 : {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋 : {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification, TFElectraForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "# KcELECTRA 모델 및 토크나이저 로드\n",
    "Kc_model = \"beomi/KcELECTRA-base\"\n",
    "Kc_tokenizer = AutoTokenizer.from_pretrained(Kc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>새로오면 다 그렇게함 열심히 하는티를 팍팍내고 뭐 바꾸고 뭐하기로 하자 압박을 주잖...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>오마쥬가 뭔진 앎?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>아 그런거야? ㅋㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>용접협회 무시하지 마라. 저기 현장 고수및 용접에 관한 전문지식 가진 대학 교수 학...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>시발 정작 지네들 자식은 몸쓰는일 안시킬거면서 개지랄떠네 ㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>용팔이</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>대구경북 당선조건 : 매국노</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>면도 뭔 스머프모자 쓰고왓네</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>여자들 물뽕 처먹여 강간하고 동영상 찍은게 죄가 아니었구나 ㅋㅋ버닝썬이 중국 삼합회...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>그래서 씨발롬아 PC가 나쁘다는 거야 좋다는 거야?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  label\n",
       "83  새로오면 다 그렇게함 열심히 하는티를 팍팍내고 뭐 바꾸고 뭐하기로 하자 압박을 주잖...      0\n",
       "53                                         오마쥬가 뭔진 앎?      0\n",
       "70                                        아 그런거야? ㅋㅋㅋ      0\n",
       "45  용접협회 무시하지 마라. 저기 현장 고수및 용접에 관한 전문지식 가진 대학 교수 학...      0\n",
       "44                시발 정작 지네들 자식은 몸쓰는일 안시킬거면서 개지랄떠네 ㅋㅋㅋ      1\n",
       "..                                                ...    ...\n",
       "57                                                용팔이      0\n",
       "75                                    대구경북 당선조건 : 매국노      1\n",
       "32                                    면도 뭔 스머프모자 쓰고왓네      0\n",
       "94  여자들 물뽕 처먹여 강간하고 동영상 찍은게 죄가 아니었구나 ㅋㅋ버닝썬이 중국 삼합회...      1\n",
       "59                       그래서 씨발롬아 PC가 나쁘다는 거야 좋다는 거야?      1\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = Kc_tokenizer( \n",
    "    list(train_data[\"Sentence\"]),           # train_data 리스트화\n",
    "    return_tensors=\"pt\",                    # pytorch의 tensor 형태로 변환\n",
    "    max_length=128,                         # 최대 토큰길이 설정\n",
    "    padding=True,                           # 학습 시 빈 값을 0으로 대체\n",
    "    truncation=True,                        # 초과 토큰 제거\n",
    "    add_special_tokens=True                 # 추가 토큰 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test_sentences = Kc_tokenizer(\n",
    "    list(test_data[\"Sentence\"]),           # test_data 리스트화\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CLS(분류 토큰)   : 시작을 알릴 때 사용 \\n\n",
    "SEP(구분자 토큰) : 서로 다를 때 구분할 사용할 토큰 \\n\n",
    "MASK            : 특정 토큰이 마스크화, 모델이 예측하도록 훈련 \\n\n",
    "PAD             : 일관된 길이로 동일하게 만듦\n",
    "                                                            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=94, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "========================================================================================================================================================================================================\n",
      "['ĠìĥĪë¡ľ', 'ìĺ¤ë©´', 'Ġëĭ¤', 'Ġê·¸ëłĩê²Į', 'íķ¨', 'ĠìĹ´ìĭ¬íŀĪ', 'ĠíķĺëĬĶ', 'íĭ°', 'ë¥¼', 'ĠíĮįíĮį', 'ëĤ´ê³ł', 'ĠëŃĲ', 'Ġë°Ķê¾¸ê³ł', 'ĠëŃĲ', 'íķĺê¸°ë¡ľ', 'ĠíķĺìŀĲ', 'Ġìķķë°ķ', 'ìĿĦ', 'Ġì£¼', 'ìŀĸëĥĲ', 'Ġ10', 'ëħĦê°Ħ', 'ĠëĦĪë¬´', 'ĠíĥĢ', 'ìĦ±ìĹĲ', 'Ġìłĸ', 'ìĸ´', 'ìĤ´', 'ìķĺëįĺ', 'ê±°', 'ĠìķĦëĭĪëĥĲ', '?', 'ĠìľĦê¸°', 'ê°Ĳ', 'ìĹĨìĿ´', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "========================================================================================================================================================================================================\n",
      "[3718, 4283, 374, 1126, 861, 2348, 644, 1629, 395, 10556, 4093, 592, 10669, 592, 17097, 3165, 7944, 279, 597, 12529, 1362, 3416, 977, 1342, 7053, 9897, 319, 928, 11517, 303, 2084, 33, 7870, 785, 1478, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_sentences[0])        # 0번째 문장에 해당하는 객체\n",
    "print(\"=\"*200) \n",
    "print(tokenized_train_sentences[0].tokens) # 0번째 문장에 토큰의 목록\n",
    "print(\"=\"*200)\n",
    "print(tokenized_train_sentences[0].ids)    # 0번째 문장에 대한 고유 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurseDataset(torch.utils.data.Dataset):                                        # 학습을 위한 데이터셋 만들기     \n",
    "    def __init__(self, encoding, labels):                                            # pytorch에서 학습할 수 있게 데이터셋 생성\n",
    "        self.encodings = encoding                                                    # Feature Data / 'Sentence'\n",
    "        self.labels = labels                                                         # Target Data / 'Label'\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} # self.encodings 딕셔너리 내의 값 중에 val를 torch.tensor로 변환해 하여\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])                             # key: toch.tensor(val[ix])라는 item 딕셔너리 형성\n",
    "        return item                                                                 # 새로운 labels 키 값에 value torch.tensor(self.labels[idx]) 쌍을 생성\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)                                                     # self.labels 길이 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set에 대한 데이터셋을 각각 생성\n",
    "train_label = train_data[\"label\"].values\n",
    "test_label = test_data[\"label\"].values\n",
    "\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=3)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kc_model = AutoModelForSequenceClassification.from_pretrained(Kc_model, num_labels=2)   # 사전 학습된 모델 찾아오기\n",
    "Kc_model.to(device)                                                                       # num_labels 평가지표 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - 2 학습 파라미터 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './results',           # 학습결과 저장경로\n",
    "    num_train_epochs=10,                # 학습 epoch 설정\n",
    "    per_device_train_batch_size = 8,    # train batch_size 설정\n",
    "    per_device_eval_batch_size = 64,    # test batch_size 설정\n",
    "    logging_dir = './logs',             # 학습 log 저장경로 / 손실 값 저장\n",
    "    logging_steps=500,                  # 학습 log 기록 단위 / 500번 마다 출력\n",
    "    save_total_limit = 2,               # 학습결과 저장 최대갯수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# 학습과정에서 사용할 평가지표를 위한 함수 설정\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  # 정밀도, 재현율, f1 구하기 \n",
    "  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "  # 정확도 구하기\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return{\n",
    "      'accuracy': acc,\n",
    "      'f1': f1,\n",
    "      'precision': precision,\n",
    "      'recall': recall\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 모듈을 사용해 모델의 학습을 컨트롤하은 trainer를 생성\n",
    "trainer = Trainer(\n",
    "    model = Kc_model,                    # 학습하고자하는 Transformers model\n",
    "    args=training_args,                  # 위에서 정의한 학습 피라미터 설정\n",
    "    train_dataset=train_dataset,         # 학습 데이터셋\n",
    "    eval_dataset=test_dataset,           # 평가 데이터셋\n",
    "    compute_metrics=compute_metrics,     # 평가지표\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "results = trainer.predict(test_dataset)\n",
    "\n",
    "# Get the true labels and predicted logits\n",
    "true_labels = results.label_ids\n",
    "predicted_logits = results.predictions.argmax(-1)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_mat = confusion_matrix(true_labels, predicted_logits)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['P', 'N'], yticklabels=['T', 'F'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: curse, 1: non_curse\n",
    "def sentence_predict(sent):\n",
    "    # 평가모드로 변경\n",
    "    Kc_model.eval()\n",
    "\n",
    "    # 입력된 문장 토크나이징\n",
    "    tokenized_sent = Kc_tokenizer(\n",
    "        sent,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    # 모델이 위치한 GPU로 이동\n",
    "    # tokenized_sent.to(deivce)\n",
    "\n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = Kc_model(\n",
    "            input_ids=tokenized_sent[\"input_ids\"],\n",
    "            attention_mask=tokenized_sent[\"attention_mask\"],\n",
    "            token_type_ids=tokenized_sent[\"token_type_ids\"]\n",
    "        )\n",
    "\n",
    "    # 결과 return\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu()\n",
    "    result = logits.argmax(-1)\n",
    "    sentence = True\n",
    "    input_sentence = tokenized_sent[\"input_ids\"]\n",
    "    if result == 0:\n",
    "        sentence = True\n",
    "\n",
    "    elif result == 1:\n",
    "        sentence = False\n",
    "    return sentence, input_sentence\n",
    "\n",
    "\n",
    "sentence_predict(\"씨발 맞아?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'RNN_2' 모듈을 가져오기 위한 경로를 sys.path에 추가\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\RNN')\n",
    " \n",
    "# 'RNN' 모듈을 import\n",
    "from RNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def badword_find(sent):\n",
    "    badword_df = pd.read_excel(r'C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\dataset\\word_list.xlsx')\n",
    "    found_bad_word = False  # 입력 문장에 단어가 발견되었는지를 나타내는 플래그\n",
    "    for idx, row in badword_df.iterrows():\n",
    "        if row[\"WORD\"] in sent:\n",
    "            # 'WORD'가 입력 문장에 포함된 경우\n",
    "            new_word = row[\"대체어\"]\n",
    "            if not pd.isnull(new_word):\n",
    "                RNN_result = sentence_generation(new_word, 2) + \" \"\n",
    "                sent = sent.replace(row[\"WORD\"], RNN_result)\n",
    "                found_bad_word = True\n",
    "            else:\n",
    "                sent = sent.replace(row[\"WORD\"], \"*\" * len(row[\"WORD\"]))\n",
    "                found_bad_word = True\n",
    "    \n",
    "    if not found_bad_word:\n",
    "        # result = \"@\" * len(input_sentence)\n",
    "        sent = \"혐오 표현입니다.\"\n",
    "    return sent\n",
    "\n",
    "# 테스트\n",
    "input_sentence = \"엄마가 죽었으면 좋겠어\"\n",
    "speak_result = badword_find(input_sentence)\n",
    "print(speak_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_pre(sent):\n",
    "    sentence = sentence_predict(sent)\n",
    "    if sentence[0] == True:\n",
    "        return sent\n",
    "    elif sentence[0] == False:\n",
    "        return badword_find(sent)\n",
    "    \n",
    "def speak(sent):\n",
    "    speak_pre(sent)\n",
    "    sentence = sentence_predict(sent)\n",
    "    if sentence == True:\n",
    "        return sent\n",
    "    elif sent == \"혐오 표현입니다.\":\n",
    "        return sent\n",
    "    elif sentence == False:\n",
    "        return badword_find(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import kss\n",
    "from pykospacing import Spacing\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "# 띄어쓰기 설정\n",
    "spacing = Spacing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 제거\n",
    "def cleanse(text):\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ|a-zA-Z0-9]','', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_repeat_normalize(text):\n",
    "    cleansed_text = cleanse(text)                                             # 특수문자 제거\n",
    "    normalized_text = repeat_normalize(cleansed_text, num_repeats=2)          # 중복문자 제거\n",
    "    input_data = re.sub(r'\\d', '', normalized_text)                           # 제거\n",
    "    normalized_text = spacing(input_data)                                     # 띄어쓰기 보정 \n",
    "\n",
    "    return normalized_text\n",
    "\n",
    "clean_and_repeat_normalize(\"아버지가방에들어가신다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_output():\n",
    "    input_text = clean_and_repeat_normalize(input())\n",
    "    sentences = kss.split_sentences(input_text)\n",
    "\n",
    "    sentences_list = []\n",
    "    for sentence in sentences:\n",
    "        speak(sentence)\n",
    "        sentences_list.append(sentence) \n",
    "\n",
    "    long_test = ' '.join(sentences_list)\n",
    "    print(long_test)\n",
    "    return long_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 씨1@발 이게 맞아?\n",
    "final_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nv37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
