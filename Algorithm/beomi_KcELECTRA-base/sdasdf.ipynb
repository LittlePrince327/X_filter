{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beomi/KcELECTRA-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18339188205533308016\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2254123828\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10314148324994524109\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Learning Device list Check \n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run KcELECTRA-base.version.py       # 필요한 라이브러리 설치\n",
    "# !pip freeze                          # 설치된 라이브러리 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# GPU 설정\n",
    "# 없을 시 CPU\n",
    "# CPU로 뜨지만, GPU 잘만 돌아감\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좌배 까는건 ㅇㅂ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>세탁이라고 봐도 된다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>애새끼가 초딩도 아니고 ㅋㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Sentence  label\n",
       "0                                    좌배 까는건 ㅇㅂ      1\n",
       "1                 집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ      0\n",
       "2  개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아      1\n",
       "3                                  세탁이라고 봐도 된다      0\n",
       "4                            애새끼가 초딩도 아니고 ㅋㅋㅋㅋ      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 엑셀 파일에서 데이터프레임 읽기\n",
    "df = pd.read_excel(r\"C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\dataset\\sample_data(100).xlsx\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_idx = df[df.label.isnull()].index                             # 해당 index에 null 값 확인\n",
    "df.loc[null_idx, \"Sentence\"]                                       # null 값이 존재한 인덱스의 Sentence 값 불러오기\n",
    "\n",
    "# lable은 Sentence의 가장 끝 문장열로 설정\n",
    "df.loc[null_idx, \"label\"] = df.loc[null_idx, \"Sentence\"].apply(lambda x: x[-1])\n",
    "\n",
    "# Sentence는 \"\\t\" 앞부분까지의 문자열로 설정\n",
    "df.loc[null_idx, \"Sentence\"] = df.loc[null_idx, \"Sentence\"].apply(lambda x: x[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 전 학습 데이터셋 : 80\n",
      "중복 제거 전 테스트 데이터셋 : 20\n",
      "중복 제거 후 학습 데이터셋 : 80\n",
      "중복 제거 후 테스트 데이터셋 : 20\n"
     ]
    }
   ],
   "source": [
    "train_data = df.sample(frac=0.8, random_state=42)                 # train(80%), test(20%) 셋 구분 \n",
    "test_data = df.drop(train_data.index)                             # 랜덤으로 샘플링(랜덤으로 숫자 배치)\n",
    "\n",
    "# 데이터셋 갯수 확인\n",
    "print('중복 제거 전 학습 데이터셋 : {}'.format(len(train_data)))\n",
    "print('중복 제거 전 테스트 데이터셋 : {}'.format(len(test_data)))\n",
    "\n",
    "# 중복 데이터 제거\n",
    "train_data.drop_duplicates(subset=[\"Sentence\"], inplace=True)\n",
    "test_data.drop_duplicates(subset=[\"Sentence\"], inplace=True)\n",
    "\n",
    "# 데이터셋 갯수 확인\n",
    "print('중복 제거 후 학습 데이터셋 : {}'.format(len(train_data)))\n",
    "print('중복 제거 후 테스트 데이터셋 : {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification, TFElectraForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "# KcELECTRA 모델 및 토크나이저 로드\n",
    "Kc_model = \"beomi/KcELECTRA-base\"\n",
    "Kc_tokenizer = AutoTokenizer.from_pretrained(Kc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = Kc_tokenizer( \n",
    "    list(train_data[\"Sentence\"]),           # train_data 리스트화\n",
    "    return_tensors=\"pt\",                    # pytorch의 tensor 형태로 변환\n",
    "    max_length=128,                         # 최대 토큰길이 설정\n",
    "    padding=True,                           # 학습 시 빈 값을 0으로 대체\n",
    "    truncation=True,                        # 초과 토큰 제거\n",
    "    add_special_tokens=True                 # 추가 토큰 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test_sentences = Kc_tokenizer(\n",
    "    list(test_data[\"Sentence\"]),           # test_data 리스트화\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCLS(분류 토큰)   : 시작을 알릴 때 사용 \\n\\nSEP(구분자 토큰) : 서로 다를 때 구분할 사용할 토큰 \\n\\nMASK            : 특정 토큰이 마스크화, 모델이 예측하도록 훈련 \\n\\nPAD             : 일관된 길이로 동일하게 만듦\\n                                                            '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CLS(분류 토큰)   : 시작을 알릴 때 사용 \\n\n",
    "SEP(구분자 토큰) : 서로 다를 때 구분할 사용할 토큰 \\n\n",
    "MASK            : 특정 토큰이 마스크화, 모델이 예측하도록 훈련 \\n\n",
    "PAD             : 일관된 길이로 동일하게 만듦\n",
    "                                                            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=94, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "========================================================================================================================================================================================================\n",
      "['ĠìĥĪë¡ľ', 'ìĺ¤ë©´', 'Ġëĭ¤', 'Ġê·¸ëłĩê²Į', 'íķ¨', 'ĠìĹ´ìĭ¬íŀĪ', 'ĠíķĺëĬĶ', 'íĭ°', 'ë¥¼', 'ĠíĮįíĮį', 'ëĤ´ê³ł', 'ĠëŃĲ', 'Ġë°Ķê¾¸ê³ł', 'ĠëŃĲ', 'íķĺê¸°ë¡ľ', 'ĠíķĺìŀĲ', 'Ġìķķë°ķ', 'ìĿĦ', 'Ġì£¼', 'ìŀĸëĥĲ', 'Ġ10', 'ëħĦê°Ħ', 'ĠëĦĪë¬´', 'ĠíĥĢ', 'ìĦ±ìĹĲ', 'Ġìłĸ', 'ìĸ´', 'ìĤ´', 'ìķĺëįĺ', 'ê±°', 'ĠìķĦëĭĪëĥĲ', '?', 'ĠìľĦê¸°', 'ê°Ĳ', 'ìĹĨìĿ´', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "========================================================================================================================================================================================================\n",
      "[3718, 4283, 374, 1126, 861, 2348, 644, 1629, 395, 10556, 4093, 592, 10669, 592, 17097, 3165, 7944, 279, 597, 12529, 1362, 3416, 977, 1342, 7053, 9897, 319, 928, 11517, 303, 2084, 33, 7870, 785, 1478, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train_sentences[0])        # 0번째 문장에 해당하는 객체\n",
    "print(\"=\"*200) \n",
    "print(tokenized_train_sentences[0].tokens) # 0번째 문장에 토큰의 목록\n",
    "print(\"=\"*200)\n",
    "print(tokenized_train_sentences[0].ids)    # 0번째 문장에 대한 고유 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurseDataset(torch.utils.data.Dataset):                                        # 학습을 위한 데이터셋 만들기     \n",
    "    def __init__(self, encoding, labels):                                            # pytorch에서 학습할 수 있게 데이터셋 생성\n",
    "        self.encodings = encoding                                                    # Feature Data / 'Sentence'\n",
    "        self.labels = labels                                                         # Target Data / 'Label'\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} # self.encodings 딕셔너리 내의 값 중에 val를 torch.tensor로 변환해 하여\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])                             # key: toch.tensor(val[ix])라는 item 딕셔너리 형성\n",
    "        return item                                                                 # 새로운 labels 키 값에 value torch.tensor(self.labels[idx]) 쌍을 생성\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)                                                     # self.labels 길이 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set에 대한 데이터셋을 각각 생성\n",
    "train_label = train_data[\"label\"].values\n",
    "test_label = test_data[\"label\"].values\n",
    "\n",
    "train_dataset = CurseDataset(tokenized_train_sentences, train_label)\n",
    "test_dataset = CurseDataset(tokenized_test_sentences, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=3)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kc_model = AutoModelForSequenceClassification.from_pretrained(Kc_model, num_labels=2)   # 사전 학습된 모델 찾아오기\n",
    "Kc_model.to(device)                                                                       # num_labels 평가지표 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - 2 학습 파라미터 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './results',           # 학습결과 저장경로\n",
    "    num_train_epochs=10,                # 학습 epoch 설정\n",
    "    per_device_train_batch_size = 8,    # train batch_size 설정\n",
    "    per_device_eval_batch_size = 64,    # test batch_size 설정\n",
    "    logging_dir = './logs',             # 학습 log 저장경로 / 손실 값 저장\n",
    "    logging_steps=500,                  # 학습 log 기록 단위 / 500번 마다 출력\n",
    "    save_total_limit = 2,               # 학습결과 저장 최대갯수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# 학습과정에서 사용할 평가지표를 위한 함수 설정\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  # 정밀도, 재현율, f1 구하기 \n",
    "  precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "  # 정확도 구하기\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return{\n",
    "      'accuracy': acc,\n",
    "      'f1': f1,\n",
    "      'precision': precision,\n",
    "      'recall': recall\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 모듈을 사용해 모델의 학습을 컨트롤하은 trainer를 생성\n",
    "trainer = Trainer(\n",
    "    model = Kc_model,                    # 학습하고자하는 Transformers model\n",
    "    args=training_args,                  # 위에서 정의한 학습 피라미터 설정\n",
    "    train_dataset=train_dataset,         # 학습 데이터셋\n",
    "    eval_dataset=test_dataset,           # 평가 데이터셋\n",
    "    compute_metrics=compute_metrics,     # 평가지표\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]C:\\Users\\GJAISCHOOL\\AppData\\Local\\Temp\\ipykernel_20024\\1869798269.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} # self.encodings 딕셔너리 내의 값 중에 val를 torch.tensor로 변환해 하여\n",
      "100%|██████████| 100/100 [04:41<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 281.1661, 'train_samples_per_second': 2.845, 'train_steps_per_second': 0.356, 'train_loss': 0.29647657394409177, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.29647657394409177, metrics={'train_runtime': 281.1661, 'train_samples_per_second': 2.845, 'train_steps_per_second': 0.356, 'train_loss': 0.29647657394409177, 'epoch': 10.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GJAISCHOOL\\AppData\\Local\\Temp\\ipykernel_20024\\1869798269.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} # self.encodings 딕셔너리 내의 값 중에 val를 torch.tensor로 변환해 하여\n",
      "100%|██████████| 1/1 [00:00<00:00, 166.53it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "results = trainer.predict(test_dataset)\n",
    "\n",
    "# Get the true labels and predicted logits\n",
    "true_labels = test_dataset.labels\n",
    "predicted_logits = results.predictions\n",
    "predicted_labels = np.argmax(predicted_logits, axis=1)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_mat = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_predict(sent):\n",
    "    # 평가모드로 변경\n",
    "    Kc_model.eval()\n",
    "\n",
    "    # 입력된 문장 토크나이징\n",
    "    tokenized_sent = Kc_tokenizer(\n",
    "        sent,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    # 모델이 위치한 GPU로 이동\n",
    "    # tokenized_sent.to(deivce)\n",
    "\n",
    "    # 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = Kc_model(\n",
    "            input_ids=tokenized_sent[\"input_ids\"],\n",
    "            attention_mask=tokenized_sent[\"attention_mask\"],\n",
    "            token_type_ids=tokenized_sent[\"token_type_ids\"]\n",
    "        )\n",
    "\n",
    "    # 결과 return\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu()\n",
    "    result = logits.argmax(-1)\n",
    "    sentence = True\n",
    "    input_sentence = tokenized_sent[\"input_ids\"]\n",
    "    if result == 0:\n",
    "        sentence = True\n",
    "\n",
    "    elif result == 1:\n",
    "        sentence = False\n",
    "    return sentence, input_sentence\n",
    "\n",
    "\n",
    "sentence_predict(\"씨발\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (2.9.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.24.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
      "\n",
      "Name: tensorflow\n",
      "Version: 2.9.3\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\gjaischool\\.conda\\envs\\nv38\\lib\\site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: pykospacing\n",
      "\n",
      "Epoch 1/200\n",
      "1214/1214 - 24s - loss: 4.2195 - accuracy: 0.2174 - 24s/epoch - 20ms/step\n",
      "Epoch 2/200\n",
      "1214/1214 - 23s - loss: 3.1312 - accuracy: 0.4086 - 23s/epoch - 19ms/step\n",
      "Epoch 3/200\n",
      "1214/1214 - 21s - loss: 2.6786 - accuracy: 0.4783 - 21s/epoch - 17ms/step\n",
      "Epoch 4/200\n",
      "1214/1214 - 21s - loss: 2.5141 - accuracy: 0.4989 - 21s/epoch - 18ms/step\n",
      "Epoch 5/200\n",
      "1214/1214 - 26s - loss: 2.4428 - accuracy: 0.5059 - 26s/epoch - 21ms/step\n",
      "Epoch 6/200\n",
      "1214/1214 - 24s - loss: 2.4042 - accuracy: 0.5072 - 24s/epoch - 20ms/step\n",
      "Epoch 7/200\n",
      "1214/1214 - 25s - loss: 2.3824 - accuracy: 0.5082 - 25s/epoch - 21ms/step\n",
      "Epoch 8/200\n",
      "1214/1214 - 20s - loss: 2.3706 - accuracy: 0.5090 - 20s/epoch - 16ms/step\n",
      "Epoch 9/200\n",
      "1214/1214 - 24s - loss: 2.3610 - accuracy: 0.5094 - 24s/epoch - 20ms/step\n",
      "Epoch 10/200\n",
      "1214/1214 - 25s - loss: 2.3562 - accuracy: 0.5104 - 25s/epoch - 20ms/step\n",
      "Epoch 11/200\n",
      "1214/1214 - 24s - loss: 2.3527 - accuracy: 0.5093 - 24s/epoch - 20ms/step\n",
      "Epoch 12/200\n",
      "1214/1214 - 24s - loss: 2.3495 - accuracy: 0.5102 - 24s/epoch - 20ms/step\n",
      "Epoch 13/200\n",
      "1214/1214 - 22s - loss: 2.3475 - accuracy: 0.5094 - 22s/epoch - 18ms/step\n",
      "Epoch 14/200\n",
      "1214/1214 - 20s - loss: 2.3463 - accuracy: 0.5092 - 20s/epoch - 17ms/step\n",
      "Epoch 15/200\n",
      "1214/1214 - 18s - loss: 2.3446 - accuracy: 0.5113 - 18s/epoch - 15ms/step\n",
      "Epoch 16/200\n",
      "1214/1214 - 19s - loss: 2.3436 - accuracy: 0.5116 - 19s/epoch - 16ms/step\n",
      "Epoch 17/200\n",
      "1214/1214 - 20s - loss: 2.3425 - accuracy: 0.5101 - 20s/epoch - 16ms/step\n",
      "Epoch 18/200\n",
      "1214/1214 - 20s - loss: 2.3411 - accuracy: 0.5105 - 20s/epoch - 17ms/step\n",
      "Epoch 19/200\n",
      "1214/1214 - 22s - loss: 2.3409 - accuracy: 0.5114 - 22s/epoch - 18ms/step\n",
      "Epoch 20/200\n",
      "1214/1214 - 24s - loss: 2.3397 - accuracy: 0.5122 - 24s/epoch - 20ms/step\n",
      "Epoch 21/200\n",
      "1214/1214 - 24s - loss: 2.3398 - accuracy: 0.5110 - 24s/epoch - 20ms/step\n",
      "Epoch 22/200\n",
      "1214/1214 - 23s - loss: 2.3394 - accuracy: 0.5101 - 23s/epoch - 19ms/step\n",
      "Epoch 23/200\n",
      "1214/1214 - 22s - loss: 2.3390 - accuracy: 0.5111 - 22s/epoch - 18ms/step\n",
      "Epoch 24/200\n",
      "1214/1214 - 21s - loss: 2.3385 - accuracy: 0.5113 - 21s/epoch - 17ms/step\n",
      "Epoch 25/200\n",
      "1214/1214 - 22s - loss: 2.3384 - accuracy: 0.5111 - 22s/epoch - 18ms/step\n",
      "Epoch 26/200\n",
      "1214/1214 - 23s - loss: 2.3376 - accuracy: 0.5123 - 23s/epoch - 19ms/step\n",
      "Epoch 27/200\n",
      "1214/1214 - 23s - loss: 2.3371 - accuracy: 0.5116 - 23s/epoch - 19ms/step\n",
      "Epoch 28/200\n",
      "1214/1214 - 26s - loss: 2.3375 - accuracy: 0.5119 - 26s/epoch - 21ms/step\n",
      "Epoch 29/200\n",
      "1214/1214 - 24s - loss: 2.3373 - accuracy: 0.5112 - 24s/epoch - 19ms/step\n",
      "Epoch 30/200\n",
      "1214/1214 - 23s - loss: 2.3372 - accuracy: 0.5116 - 23s/epoch - 19ms/step\n",
      "Epoch 31/200\n",
      "1214/1214 - 23s - loss: 2.3361 - accuracy: 0.5120 - 23s/epoch - 19ms/step\n",
      "Epoch 32/200\n",
      "1214/1214 - 20s - loss: 2.3364 - accuracy: 0.5107 - 20s/epoch - 17ms/step\n",
      "Epoch 33/200\n",
      "1214/1214 - 26s - loss: 2.3359 - accuracy: 0.5121 - 26s/epoch - 21ms/step\n",
      "Epoch 34/200\n",
      "1214/1214 - 25s - loss: 2.3360 - accuracy: 0.5119 - 25s/epoch - 20ms/step\n",
      "Epoch 35/200\n",
      "1214/1214 - 23s - loss: 2.3354 - accuracy: 0.5126 - 23s/epoch - 19ms/step\n",
      "Epoch 36/200\n",
      "1214/1214 - 24s - loss: 2.3354 - accuracy: 0.5124 - 24s/epoch - 20ms/step\n",
      "Epoch 37/200\n",
      "1214/1214 - 24s - loss: 2.3356 - accuracy: 0.5111 - 24s/epoch - 20ms/step\n",
      "Epoch 38/200\n",
      "1214/1214 - 25s - loss: 2.3353 - accuracy: 0.5113 - 25s/epoch - 21ms/step\n",
      "Epoch 39/200\n",
      "1214/1214 - 24s - loss: 2.3346 - accuracy: 0.5111 - 24s/epoch - 20ms/step\n",
      "Epoch 40/200\n",
      "1214/1214 - 24s - loss: 2.3352 - accuracy: 0.5122 - 24s/epoch - 20ms/step\n",
      "Epoch 41/200\n",
      "1214/1214 - 24s - loss: 2.3354 - accuracy: 0.5112 - 24s/epoch - 20ms/step\n",
      "Epoch 42/200\n",
      "1214/1214 - 24s - loss: 2.3345 - accuracy: 0.5124 - 24s/epoch - 19ms/step\n",
      "Epoch 43/200\n",
      "1214/1214 - 24s - loss: 2.3344 - accuracy: 0.5121 - 24s/epoch - 20ms/step\n",
      "Epoch 44/200\n",
      "1214/1214 - 23s - loss: 2.3345 - accuracy: 0.5115 - 23s/epoch - 19ms/step\n",
      "Epoch 45/200\n",
      "1214/1214 - 24s - loss: 2.3341 - accuracy: 0.5113 - 24s/epoch - 20ms/step\n",
      "Epoch 46/200\n",
      "1214/1214 - 24s - loss: 2.3347 - accuracy: 0.5116 - 24s/epoch - 20ms/step\n",
      "Epoch 47/200\n",
      "1214/1214 - 24s - loss: 2.3337 - accuracy: 0.5112 - 24s/epoch - 19ms/step\n",
      "Epoch 48/200\n",
      "1214/1214 - 24s - loss: 2.3340 - accuracy: 0.5122 - 24s/epoch - 20ms/step\n",
      "Epoch 49/200\n",
      "1214/1214 - 24s - loss: 2.3341 - accuracy: 0.5129 - 24s/epoch - 20ms/step\n",
      "Epoch 50/200\n",
      "1214/1214 - 24s - loss: 2.3341 - accuracy: 0.5120 - 24s/epoch - 20ms/step\n",
      "Epoch 51/200\n",
      "1214/1214 - 24s - loss: 2.3342 - accuracy: 0.5119 - 24s/epoch - 19ms/step\n",
      "Epoch 52/200\n",
      "1214/1214 - 23s - loss: 2.3338 - accuracy: 0.5122 - 23s/epoch - 19ms/step\n",
      "Epoch 53/200\n",
      "1214/1214 - 23s - loss: 2.3344 - accuracy: 0.5122 - 23s/epoch - 19ms/step\n",
      "Epoch 54/200\n",
      "1214/1214 - 24s - loss: 2.3336 - accuracy: 0.5116 - 24s/epoch - 20ms/step\n",
      "Epoch 55/200\n",
      "1214/1214 - 24s - loss: 2.3330 - accuracy: 0.5120 - 24s/epoch - 20ms/step\n",
      "Epoch 56/200\n",
      "1214/1214 - 23s - loss: 2.3336 - accuracy: 0.5118 - 23s/epoch - 19ms/step\n",
      "Epoch 57/200\n",
      "1214/1214 - 23s - loss: 2.3331 - accuracy: 0.5122 - 23s/epoch - 19ms/step\n",
      "Epoch 58/200\n",
      "1214/1214 - 24s - loss: 2.3336 - accuracy: 0.5117 - 24s/epoch - 20ms/step\n",
      "Epoch 59/200\n",
      "1214/1214 - 25s - loss: 2.3329 - accuracy: 0.5118 - 25s/epoch - 21ms/step\n",
      "Epoch 60/200\n",
      "1214/1214 - 25s - loss: 2.3337 - accuracy: 0.5119 - 25s/epoch - 20ms/step\n",
      "Epoch 61/200\n",
      "1214/1214 - 25s - loss: 2.3331 - accuracy: 0.5119 - 25s/epoch - 21ms/step\n",
      "Epoch 62/200\n",
      "1214/1214 - 26s - loss: 2.3331 - accuracy: 0.5124 - 26s/epoch - 21ms/step\n",
      "Epoch 63/200\n",
      "1214/1214 - 26s - loss: 2.3329 - accuracy: 0.5120 - 26s/epoch - 22ms/step\n",
      "Epoch 64/200\n",
      "1214/1214 - 26s - loss: 2.3332 - accuracy: 0.5118 - 26s/epoch - 21ms/step\n",
      "Epoch 65/200\n",
      "1214/1214 - 27s - loss: 2.3333 - accuracy: 0.5116 - 27s/epoch - 22ms/step\n",
      "Epoch 66/200\n",
      "1214/1214 - 26s - loss: 2.3331 - accuracy: 0.5122 - 26s/epoch - 21ms/step\n",
      "Epoch 67/200\n",
      "1214/1214 - 26s - loss: 2.3330 - accuracy: 0.5125 - 26s/epoch - 21ms/step\n",
      "Epoch 68/200\n",
      "1214/1214 - 25s - loss: 2.3331 - accuracy: 0.5111 - 25s/epoch - 21ms/step\n",
      "Epoch 69/200\n",
      "1214/1214 - 24s - loss: 2.3332 - accuracy: 0.5123 - 24s/epoch - 20ms/step\n",
      "Epoch 70/200\n",
      "1214/1214 - 26s - loss: 2.3332 - accuracy: 0.5119 - 26s/epoch - 21ms/step\n",
      "Epoch 71/200\n",
      "1214/1214 - 26s - loss: 2.3334 - accuracy: 0.5116 - 26s/epoch - 22ms/step\n",
      "Epoch 72/200\n",
      "1214/1214 - 29s - loss: 2.3319 - accuracy: 0.5123 - 29s/epoch - 24ms/step\n",
      "Epoch 73/200\n",
      "1214/1214 - 26s - loss: 2.3325 - accuracy: 0.5125 - 26s/epoch - 21ms/step\n",
      "Epoch 74/200\n",
      "1214/1214 - 26s - loss: 2.3322 - accuracy: 0.5119 - 26s/epoch - 21ms/step\n",
      "Epoch 75/200\n",
      "1214/1214 - 25s - loss: 2.3328 - accuracy: 0.5109 - 25s/epoch - 20ms/step\n",
      "Epoch 76/200\n",
      "1214/1214 - 25s - loss: 2.3325 - accuracy: 0.5126 - 25s/epoch - 21ms/step\n",
      "Epoch 77/200\n",
      "1214/1214 - 29s - loss: 2.3325 - accuracy: 0.5112 - 29s/epoch - 24ms/step\n",
      "Epoch 78/200\n",
      "1214/1214 - 29s - loss: 2.3332 - accuracy: 0.5118 - 29s/epoch - 24ms/step\n",
      "Epoch 79/200\n",
      "1214/1214 - 27s - loss: 2.3326 - accuracy: 0.5119 - 27s/epoch - 22ms/step\n",
      "Epoch 80/200\n",
      "1214/1214 - 25s - loss: 2.3322 - accuracy: 0.5122 - 25s/epoch - 21ms/step\n",
      "Epoch 81/200\n",
      "1214/1214 - 25s - loss: 2.3323 - accuracy: 0.5126 - 25s/epoch - 20ms/step\n",
      "Epoch 82/200\n",
      "1214/1214 - 27s - loss: 2.3322 - accuracy: 0.5118 - 27s/epoch - 22ms/step\n",
      "Epoch 83/200\n",
      "1214/1214 - 27s - loss: 2.3325 - accuracy: 0.5118 - 27s/epoch - 22ms/step\n",
      "Epoch 84/200\n",
      "1214/1214 - 29s - loss: 2.3328 - accuracy: 0.5116 - 29s/epoch - 24ms/step\n",
      "Epoch 85/200\n",
      "1214/1214 - 27s - loss: 2.3324 - accuracy: 0.5122 - 27s/epoch - 22ms/step\n",
      "Epoch 86/200\n",
      "1214/1214 - 26s - loss: 2.3328 - accuracy: 0.5116 - 26s/epoch - 21ms/step\n",
      "Epoch 87/200\n",
      "1214/1214 - 26s - loss: 2.3323 - accuracy: 0.5113 - 26s/epoch - 21ms/step\n",
      "Epoch 88/200\n",
      "1214/1214 - 24s - loss: 2.3323 - accuracy: 0.5123 - 24s/epoch - 20ms/step\n",
      "Epoch 89/200\n",
      "1214/1214 - 26s - loss: 2.3324 - accuracy: 0.5115 - 26s/epoch - 21ms/step\n",
      "Epoch 90/200\n",
      "1214/1214 - 27s - loss: 2.3331 - accuracy: 0.5116 - 27s/epoch - 23ms/step\n",
      "Epoch 91/200\n",
      "1214/1214 - 25s - loss: 2.3319 - accuracy: 0.5121 - 25s/epoch - 21ms/step\n",
      "Epoch 92/200\n",
      "1214/1214 - 25s - loss: 2.3321 - accuracy: 0.5126 - 25s/epoch - 20ms/step\n",
      "Epoch 93/200\n",
      "1214/1214 - 26s - loss: 2.3324 - accuracy: 0.5119 - 26s/epoch - 22ms/step\n",
      "Epoch 94/200\n",
      "1214/1214 - 23s - loss: 2.3321 - accuracy: 0.5110 - 23s/epoch - 19ms/step\n",
      "Epoch 95/200\n",
      "1214/1214 - 22s - loss: 2.3320 - accuracy: 0.5122 - 22s/epoch - 18ms/step\n",
      "Epoch 96/200\n",
      "1214/1214 - 21s - loss: 2.3323 - accuracy: 0.5119 - 21s/epoch - 17ms/step\n",
      "Epoch 97/200\n",
      "1214/1214 - 21s - loss: 2.3321 - accuracy: 0.5112 - 21s/epoch - 17ms/step\n",
      "Epoch 98/200\n",
      "1214/1214 - 22s - loss: 2.3319 - accuracy: 0.5123 - 22s/epoch - 18ms/step\n",
      "Epoch 99/200\n",
      "1214/1214 - 22s - loss: 2.3321 - accuracy: 0.5120 - 22s/epoch - 19ms/step\n",
      "Epoch 100/200\n",
      "1214/1214 - 25s - loss: 2.3318 - accuracy: 0.5120 - 25s/epoch - 21ms/step\n",
      "Epoch 101/200\n",
      "1214/1214 - 26s - loss: 2.3320 - accuracy: 0.5118 - 26s/epoch - 21ms/step\n",
      "Epoch 102/200\n",
      "1214/1214 - 25s - loss: 2.3312 - accuracy: 0.5121 - 25s/epoch - 20ms/step\n",
      "Epoch 103/200\n",
      "1214/1214 - 25s - loss: 2.3322 - accuracy: 0.5118 - 25s/epoch - 20ms/step\n",
      "Epoch 104/200\n",
      "1214/1214 - 23s - loss: 2.3324 - accuracy: 0.5120 - 23s/epoch - 19ms/step\n",
      "Epoch 105/200\n",
      "1214/1214 - 22s - loss: 2.3320 - accuracy: 0.5123 - 22s/epoch - 18ms/step\n",
      "Epoch 106/200\n",
      "1214/1214 - 24s - loss: 2.3314 - accuracy: 0.5115 - 24s/epoch - 20ms/step\n",
      "Epoch 107/200\n",
      "1214/1214 - 21s - loss: 2.3316 - accuracy: 0.5120 - 21s/epoch - 17ms/step\n",
      "Epoch 108/200\n",
      "1214/1214 - 23s - loss: 2.3317 - accuracy: 0.5123 - 23s/epoch - 19ms/step\n",
      "Epoch 109/200\n",
      "1214/1214 - 23s - loss: 2.3319 - accuracy: 0.5121 - 23s/epoch - 19ms/step\n",
      "Epoch 110/200\n",
      "1214/1214 - 22s - loss: 2.3318 - accuracy: 0.5123 - 22s/epoch - 18ms/step\n",
      "Epoch 111/200\n",
      "1214/1214 - 23s - loss: 2.3323 - accuracy: 0.5120 - 23s/epoch - 19ms/step\n",
      "Epoch 112/200\n",
      "1214/1214 - 23s - loss: 2.3313 - accuracy: 0.5118 - 23s/epoch - 19ms/step\n",
      "Epoch 113/200\n",
      "1214/1214 - 24s - loss: 2.3318 - accuracy: 0.5123 - 24s/epoch - 19ms/step\n",
      "Epoch 114/200\n",
      "1214/1214 - 23s - loss: 2.3317 - accuracy: 0.5109 - 23s/epoch - 19ms/step\n",
      "Epoch 115/200\n",
      "1214/1214 - 23s - loss: 2.3317 - accuracy: 0.5112 - 23s/epoch - 19ms/step\n",
      "Epoch 116/200\n",
      "1214/1214 - 23s - loss: 2.3320 - accuracy: 0.5126 - 23s/epoch - 19ms/step\n",
      "Epoch 117/200\n",
      "1214/1214 - 23s - loss: 2.3315 - accuracy: 0.5114 - 23s/epoch - 19ms/step\n",
      "Epoch 118/200\n",
      "1214/1214 - 23s - loss: 2.3316 - accuracy: 0.5129 - 23s/epoch - 19ms/step\n",
      "Epoch 119/200\n",
      "1214/1214 - 23s - loss: 2.3325 - accuracy: 0.5115 - 23s/epoch - 19ms/step\n",
      "Epoch 120/200\n",
      "1214/1214 - 24s - loss: 2.3321 - accuracy: 0.5112 - 24s/epoch - 19ms/step\n",
      "Epoch 121/200\n",
      "1214/1214 - 23s - loss: 2.3315 - accuracy: 0.5110 - 23s/epoch - 19ms/step\n",
      "Epoch 122/200\n",
      "1214/1214 - 23s - loss: 2.3323 - accuracy: 0.5114 - 23s/epoch - 19ms/step\n",
      "Epoch 123/200\n",
      "1214/1214 - 22s - loss: 2.3312 - accuracy: 0.5114 - 22s/epoch - 18ms/step\n",
      "Epoch 124/200\n",
      "1214/1214 - 21s - loss: 2.3320 - accuracy: 0.5114 - 21s/epoch - 17ms/step\n",
      "Epoch 125/200\n",
      "1214/1214 - 23s - loss: 2.3316 - accuracy: 0.5128 - 23s/epoch - 19ms/step\n",
      "Epoch 126/200\n",
      "1214/1214 - 24s - loss: 2.3318 - accuracy: 0.5128 - 24s/epoch - 20ms/step\n",
      "Epoch 127/200\n",
      "1214/1214 - 25s - loss: 2.3316 - accuracy: 0.5115 - 25s/epoch - 20ms/step\n",
      "Epoch 128/200\n",
      "1214/1214 - 25s - loss: 2.3311 - accuracy: 0.5122 - 25s/epoch - 20ms/step\n",
      "Epoch 129/200\n",
      "1214/1214 - 25s - loss: 2.3310 - accuracy: 0.5122 - 25s/epoch - 21ms/step\n",
      "Epoch 130/200\n",
      "1214/1214 - 26s - loss: 2.3315 - accuracy: 0.5116 - 26s/epoch - 21ms/step\n",
      "Epoch 131/200\n",
      "1214/1214 - 29s - loss: 2.3315 - accuracy: 0.5125 - 29s/epoch - 24ms/step\n",
      "Epoch 132/200\n",
      "1214/1214 - 28s - loss: 2.3312 - accuracy: 0.5120 - 28s/epoch - 23ms/step\n",
      "Epoch 133/200\n",
      "1214/1214 - 27s - loss: 2.3316 - accuracy: 0.5115 - 27s/epoch - 22ms/step\n",
      "Epoch 134/200\n",
      "1214/1214 - 26s - loss: 2.3314 - accuracy: 0.5128 - 26s/epoch - 22ms/step\n",
      "Epoch 135/200\n",
      "1214/1214 - 27s - loss: 2.3314 - accuracy: 0.5123 - 27s/epoch - 22ms/step\n",
      "Epoch 136/200\n",
      "1214/1214 - 26s - loss: 2.3318 - accuracy: 0.5114 - 26s/epoch - 22ms/step\n",
      "Epoch 137/200\n",
      "1214/1214 - 27s - loss: 2.3313 - accuracy: 0.5116 - 27s/epoch - 22ms/step\n",
      "Epoch 138/200\n",
      "1214/1214 - 29s - loss: 2.3317 - accuracy: 0.5123 - 29s/epoch - 24ms/step\n",
      "Epoch 139/200\n",
      "1214/1214 - 27s - loss: 2.3316 - accuracy: 0.5124 - 27s/epoch - 23ms/step\n",
      "Epoch 140/200\n",
      "1214/1214 - 25s - loss: 2.3315 - accuracy: 0.5110 - 25s/epoch - 21ms/step\n",
      "Epoch 141/200\n",
      "1214/1214 - 25s - loss: 2.3311 - accuracy: 0.5117 - 25s/epoch - 20ms/step\n",
      "Epoch 142/200\n",
      "1214/1214 - 25s - loss: 2.3310 - accuracy: 0.5124 - 25s/epoch - 21ms/step\n",
      "Epoch 143/200\n",
      "1214/1214 - 29s - loss: 2.3318 - accuracy: 0.5119 - 29s/epoch - 24ms/step\n",
      "Epoch 144/200\n",
      "1214/1214 - 28s - loss: 2.3315 - accuracy: 0.5119 - 28s/epoch - 23ms/step\n",
      "Epoch 145/200\n",
      "1214/1214 - 27s - loss: 2.3315 - accuracy: 0.5113 - 27s/epoch - 22ms/step\n",
      "Epoch 146/200\n",
      "1214/1214 - 28s - loss: 2.3312 - accuracy: 0.5112 - 28s/epoch - 23ms/step\n",
      "Epoch 147/200\n",
      "1214/1214 - 27s - loss: 2.3308 - accuracy: 0.5123 - 27s/epoch - 22ms/step\n",
      "Epoch 148/200\n",
      "1214/1214 - 26s - loss: 2.3310 - accuracy: 0.5127 - 26s/epoch - 22ms/step\n",
      "Epoch 149/200\n",
      "1214/1214 - 27s - loss: 2.3313 - accuracy: 0.5124 - 27s/epoch - 22ms/step\n",
      "Epoch 150/200\n",
      "1214/1214 - 27s - loss: 2.3309 - accuracy: 0.5127 - 27s/epoch - 23ms/step\n",
      "Epoch 151/200\n",
      "1214/1214 - 26s - loss: 2.3305 - accuracy: 0.5116 - 26s/epoch - 22ms/step\n",
      "Epoch 152/200\n",
      "1214/1214 - 29s - loss: 2.3315 - accuracy: 0.5115 - 29s/epoch - 24ms/step\n",
      "Epoch 153/200\n",
      "1214/1214 - 32s - loss: 2.3304 - accuracy: 0.5127 - 32s/epoch - 26ms/step\n",
      "Epoch 154/200\n",
      "1214/1214 - 31s - loss: 2.3309 - accuracy: 0.5116 - 31s/epoch - 26ms/step\n",
      "Epoch 155/200\n",
      "1214/1214 - 31s - loss: 2.3309 - accuracy: 0.5118 - 31s/epoch - 26ms/step\n",
      "Epoch 156/200\n",
      "1214/1214 - 28s - loss: 2.3311 - accuracy: 0.5116 - 28s/epoch - 23ms/step\n",
      "Epoch 157/200\n",
      "1214/1214 - 28s - loss: 2.3309 - accuracy: 0.5107 - 28s/epoch - 23ms/step\n",
      "Epoch 158/200\n",
      "1214/1214 - 28s - loss: 2.3307 - accuracy: 0.5116 - 28s/epoch - 23ms/step\n",
      "Epoch 159/200\n",
      "1214/1214 - 30s - loss: 2.3311 - accuracy: 0.5116 - 30s/epoch - 25ms/step\n",
      "Epoch 160/200\n",
      "1214/1214 - 30s - loss: 2.3312 - accuracy: 0.5123 - 30s/epoch - 25ms/step\n",
      "Epoch 161/200\n",
      "1214/1214 - 26s - loss: 2.3309 - accuracy: 0.5113 - 26s/epoch - 22ms/step\n",
      "Epoch 162/200\n",
      "1214/1214 - 24s - loss: 2.3310 - accuracy: 0.5125 - 24s/epoch - 20ms/step\n",
      "Epoch 163/200\n",
      "1214/1214 - 25s - loss: 2.3310 - accuracy: 0.5119 - 25s/epoch - 21ms/step\n",
      "Epoch 164/200\n",
      "1214/1214 - 25s - loss: 2.3302 - accuracy: 0.5127 - 25s/epoch - 21ms/step\n",
      "Epoch 165/200\n",
      "1214/1214 - 24s - loss: 2.3307 - accuracy: 0.5125 - 24s/epoch - 20ms/step\n",
      "Epoch 166/200\n",
      "1214/1214 - 24s - loss: 2.3308 - accuracy: 0.5129 - 24s/epoch - 20ms/step\n",
      "Epoch 167/200\n",
      "1214/1214 - 25s - loss: 2.3313 - accuracy: 0.5117 - 25s/epoch - 21ms/step\n",
      "Epoch 168/200\n",
      "1214/1214 - 29s - loss: 2.3310 - accuracy: 0.5120 - 29s/epoch - 24ms/step\n",
      "Epoch 169/200\n",
      "1214/1214 - 26s - loss: 2.3310 - accuracy: 0.5121 - 26s/epoch - 22ms/step\n",
      "Epoch 170/200\n",
      "1214/1214 - 27s - loss: 2.3307 - accuracy: 0.5117 - 27s/epoch - 22ms/step\n",
      "Epoch 171/200\n",
      "1214/1214 - 47s - loss: 2.3309 - accuracy: 0.5121 - 47s/epoch - 39ms/step\n",
      "Epoch 172/200\n",
      "1214/1214 - 37s - loss: 2.3304 - accuracy: 0.5122 - 37s/epoch - 31ms/step\n",
      "Epoch 173/200\n",
      "1214/1214 - 36s - loss: 2.3306 - accuracy: 0.5118 - 36s/epoch - 30ms/step\n",
      "Epoch 174/200\n",
      "1214/1214 - 39s - loss: 2.3311 - accuracy: 0.5123 - 39s/epoch - 32ms/step\n",
      "Epoch 175/200\n",
      "1214/1214 - 40s - loss: 2.3312 - accuracy: 0.5114 - 40s/epoch - 33ms/step\n",
      "Epoch 176/200\n",
      "1214/1214 - 38s - loss: 2.3307 - accuracy: 0.5117 - 38s/epoch - 31ms/step\n",
      "Epoch 177/200\n",
      "1214/1214 - 35s - loss: 2.3310 - accuracy: 0.5119 - 35s/epoch - 29ms/step\n",
      "Epoch 178/200\n",
      "1214/1214 - 37s - loss: 2.3304 - accuracy: 0.5130 - 37s/epoch - 31ms/step\n",
      "Epoch 179/200\n",
      "1214/1214 - 36s - loss: 2.3303 - accuracy: 0.5115 - 36s/epoch - 30ms/step\n",
      "Epoch 180/200\n",
      "1214/1214 - 38s - loss: 2.3308 - accuracy: 0.5119 - 38s/epoch - 31ms/step\n",
      "Epoch 181/200\n",
      "1214/1214 - 34s - loss: 2.3306 - accuracy: 0.5117 - 34s/epoch - 28ms/step\n",
      "Epoch 182/200\n",
      "1214/1214 - 36s - loss: 2.3309 - accuracy: 0.5112 - 36s/epoch - 30ms/step\n",
      "Epoch 183/200\n",
      "1214/1214 - 38s - loss: 2.3306 - accuracy: 0.5114 - 38s/epoch - 31ms/step\n",
      "Epoch 184/200\n",
      "1214/1214 - 36s - loss: 2.3306 - accuracy: 0.5121 - 36s/epoch - 30ms/step\n",
      "Epoch 185/200\n",
      "1214/1214 - 34s - loss: 2.3304 - accuracy: 0.5113 - 34s/epoch - 28ms/step\n",
      "Epoch 186/200\n",
      "1214/1214 - 36s - loss: 2.3310 - accuracy: 0.5120 - 36s/epoch - 29ms/step\n",
      "Epoch 187/200\n",
      "1214/1214 - 37s - loss: 2.3302 - accuracy: 0.5121 - 37s/epoch - 30ms/step\n",
      "Epoch 188/200\n",
      "1214/1214 - 31s - loss: 2.3306 - accuracy: 0.5125 - 31s/epoch - 25ms/step\n",
      "Epoch 189/200\n",
      "1214/1214 - 29s - loss: 2.3309 - accuracy: 0.5121 - 29s/epoch - 24ms/step\n",
      "Epoch 190/200\n",
      "1214/1214 - 29s - loss: 2.3304 - accuracy: 0.5121 - 29s/epoch - 24ms/step\n",
      "Epoch 191/200\n",
      "1214/1214 - 27s - loss: 2.3305 - accuracy: 0.5127 - 27s/epoch - 22ms/step\n",
      "Epoch 192/200\n",
      "1214/1214 - 31s - loss: 2.3304 - accuracy: 0.5129 - 31s/epoch - 26ms/step\n",
      "Epoch 193/200\n",
      "1214/1214 - 28s - loss: 2.3304 - accuracy: 0.5115 - 28s/epoch - 23ms/step\n",
      "Epoch 194/200\n",
      "1214/1214 - 25s - loss: 2.3306 - accuracy: 0.5112 - 25s/epoch - 21ms/step\n",
      "Epoch 195/200\n",
      "1214/1214 - 25s - loss: 2.3307 - accuracy: 0.5123 - 25s/epoch - 21ms/step\n",
      "Epoch 196/200\n",
      "1214/1214 - 26s - loss: 2.3303 - accuracy: 0.5125 - 26s/epoch - 21ms/step\n",
      "Epoch 197/200\n",
      "1214/1214 - 26s - loss: 2.3301 - accuracy: 0.5112 - 26s/epoch - 21ms/step\n",
      "Epoch 198/200\n",
      "1214/1214 - 25s - loss: 2.3301 - accuracy: 0.5128 - 25s/epoch - 21ms/step\n",
      "Epoch 199/200\n",
      "1214/1214 - 28s - loss: 2.3303 - accuracy: 0.5121 - 28s/epoch - 23ms/step\n",
      "Epoch 200/200\n",
      "1214/1214 - 23s - loss: 2.3304 - accuracy: 0.5121 - 23s/epoch - 19ms/step\n"
     ]
    }
   ],
   "source": [
    "# 'RNN_2' 모듈을 가져오기 위한 경로를 sys.path에 추가\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\RNN')\n",
    " \n",
    "# 'RNN' 모듈을 import\n",
    "from RNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혐오 표현입니다.\n"
     ]
    }
   ],
   "source": [
    "def badword_find(sent):\n",
    "    badword_df = pd.read_excel(r'C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\dataset\\word_list.xlsx')\n",
    "    found_bad_word = False  # 입력 문장에 단어가 발견되었는지를 나타내는 플래그\n",
    "    for idx, row in badword_df.iterrows():\n",
    "        if row[\"WORD\"] in sent:\n",
    "            # 'WORD'가 입력 문장에 포함된 경우\n",
    "            new_word = row[\"대체어\"]\n",
    "            if not pd.isnull(new_word):\n",
    "                RNN_result = sentence_generation(new_word, 2) + \" \"\n",
    "                sent = sent.replace(row[\"WORD\"], RNN_result)\n",
    "                found_bad_word = True\n",
    "            else:\n",
    "                sent = sent.replace(row[\"WORD\"], \"*\" * len(row[\"WORD\"]))\n",
    "                found_bad_word = True\n",
    "    \n",
    "    if not found_bad_word:\n",
    "        # result = \"@\" * len(input_sentence)\n",
    "        sent = \"혐오 표현입니다.\"\n",
    "    return sent\n",
    "\n",
    "# 테스트\n",
    "input_sentence = \"엄마가 죽었으면 좋겠어\"\n",
    "speak_result = badword_find(input_sentence)\n",
    "print(speak_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_pre(sent):\n",
    "    sentence = sentence_predict(sent)\n",
    "    if sentence[0] == True:\n",
    "        return sent\n",
    "    elif sentence[0] == False:\n",
    "        return badword_find(sent)\n",
    "    \n",
    "def speak(sent):\n",
    "    speak_pre(sent)\n",
    "    sentence = sentence_predict(sent)\n",
    "    if sentence == True:\n",
    "        return sent\n",
    "    elif sent == \"혐오 표현입니다.\":\n",
    "        return sent\n",
    "    elif sentence == False:\n",
    "        return badword_find(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import kss\n",
    "from pykospacing import Spacing\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "# 띄어쓰기 설정\n",
    "spacing = Spacing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 제거\n",
    "def cleanse(text):\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    text = re.sub(pattern, ' ', text)\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ|a-zA-Z0-9]','', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아버지가 방에 들어가신다'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_and_repeat_normalize(text):\n",
    "    cleansed_text = cleanse(text)                                             # 특수문자 제거\n",
    "    normalized_text = repeat_normalize(cleansed_text, num_repeats=2)          # 중복문자 제거\n",
    "    input_data = re.sub(r'\\d', '', normalized_text)                           # 제거\n",
    "    normalized_text = spacing(input_data)                                     # 띄어쓰기 보정 \n",
    "\n",
    "    return normalized_text\n",
    "\n",
    "clean_and_repeat_normalize(\"아버지가방에들어가신다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_output():\n",
    "    input_text = clean_and_repeat_normalize(input())\n",
    "    sentences = kss.split_sentences(input_text)\n",
    "\n",
    "    sentences_list = []\n",
    "    for sentence in sentences:\n",
    "        speak(sentence)\n",
    "        sentences_list.append(sentence) \n",
    "\n",
    "    long_test = ' '.join(sentences_list)\n",
    "    print(long_test)\n",
    "    return long_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "씨발\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'씨발'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 씨1@발 이게 맞아?\n",
    "final_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nv37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
