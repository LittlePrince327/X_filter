{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>세탁이라고 봐도 된다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>은행에 대출 상담 받으러 가보면 직업의 귀천 바로 알려줌</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ㅋㅋㅋㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ㄹㅇㅋㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Sentence  label\n",
       "0     집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ      0\n",
       "1                      세탁이라고 봐도 된다      0\n",
       "2  은행에 대출 상담 받으러 가보면 직업의 귀천 바로 알려줌      0\n",
       "3                            ㅋㅋㅋㅋㅋ      0\n",
       "4                            ㄹㅇㅋㅋㅋ      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r'C:/Users/GJAISCHOOL/Desktop/X_filter/Algorithm/dataset/good_sentence.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 545\n",
      "{'다': 1, '그냥': 2, 'ㅋㅋ': 3, '이게': 4, '난': 5, '누가': 6, '나': 7, '아': 8, 'ㄹㅇ': 9, '바로': 10, '아예': 11, '아이디': 12, '비번': 13, '파일에': 14, '등등': 15, 'ㅋㅋㅋ': 16, '말이': 17, '여기': 18, '뭐': 19, '너무': 20, '오이': 21, '강력계': 22, '니가': 23, '그': 24, 'ㅋㅋㅋㅋ': 25, '집에': 26, '롱': 27, '패딩만': 28, '세': 29, '개다': 30, '10년': 31, '더': 32, '입어야지': 33, '세탁이라고': 34, '봐도': 35, '된다': 36, '은행에': 37, '대출': 38, '상담': 39, '받으러': 40, '가보면': 41, '직업의': 42, '귀천': 43, '알려줌': 44, 'ㅋㅋㅋㅋㅋ': 45, 'ㄹㅇㅋㅋㅋ': 46, '우리지역군데': 47, '금태섭': 48, '뽑으면': 49, '안되지': 50, '그래도': 51, '자한당': 52, '뻡아야겠지': 53, '백정주제에': 54, '라고하는걸': 55, '비하라고': 56, '느낀다면': 57, '본인조차': 58, '직업에': 59, '자부심이': 60, '없는건데': 61, '백인': 62, '탓이랑께': 63, '마감시간': 64, '다돼서': 65, '떨이하는': 66, '고기': 67, '사먹으면': 68, '식중독': 69, '518퍼네아': 70, '오래': 71, '된': 72, '것도': 73, '새': 74, '거처럼': 75, '둔갑해서': 76, '다음날': 77, '팔테니': 78, '떨이라는': 79, '개념이': 80, '없을라나': 81, '열사발': 82, '들이켜도': 83, '아깝지': 84, '않음': 85, '으따': 86, '옷': 87, '이딴건': 88, '필요': 89, '없당깨': 90, '현금으로': 91, '달랑깨': 92, '사이트': 93, '마다': 94, '다르고': 95, '난이도': 96, '높음엑셀': 97, '모든': 98, '계좌정보': 99, '들어': 100, '있고이': 101, '엑셀': 102, '비번만': 103, '기억함': 104, 'ㅇㅈ': 105, '저런거에': 106, '앉아어': 107, '감전사': 108, '당할': 109, '수도': 110, '근데': 111, '그것': 112, '요즘': 113, '살짝': 114, '트렌드': 115, '지났더라': 116, '군대에서': 117, '여군이': 118, '필요한가': 119, 'ㅋㅋ복수할겨': 120, '면도': 121, '뭔': 122, '스머프모자': 123, '쓰고왓네': 124, '사형': 125, '예지': 126, '당연히': 127, '많이볼수밖에': 128, '흑종원': 129, 'ㅋㅋㅋㅋㅋㅋㅋㅋ': 130, '호주에서는': 131, '남자들이': 132, '동물보다': 133, '못한존재라던데ㅋㅋ': 134, '나베가': 135, '나베했네요': 136, '행함이': 137, '없어도': 138, '불경건한': 139, '자를': 140, '의롭다': 141, '하시는': 142, '그분을': 143, '믿는': 144, '사람에게는': 145, '그의': 146, '믿음이': 147, '의로': 148, '여겨지느니라': 149, '뭐래냐': 150, '용접협회': 151, '무시하지': 152, '마라': 153, '저기': 154, '현장': 155, '고수및': 156, '용접에': 157, '관한': 158, '전문지식': 159, '가진': 160, '대학': 161, '교수': 162, '학자들': 163, '모임이다': 164, '파워력': 165, '쎄다': 166, '너도': 167, '해': 168, '안하는': 169, '애들도': 170, '결국': 171, '학업에': 172, '흥미를': 173, '못': 174, '느꼈다는거니까': 175, '홀딩하세요': 176, '만': 177, '나이': 178, '공식화도': 179, '선거철에': 180, '지': 181, '지지자': 182, '결집시키는거임': 183, '자기': 184, '지지층엔': 185, '아시아인이': 186, '별로': 187, '없고': 188, '이민자들': 189, '싫어하는': 190, '사람들이': 191, '대부분이니까': 192, '오마쥬가': 193, '뭔진': 194, '앎': 195, '4카': 196, '성공': 197, '쓰레기들은': 198, '휴지통으로': 199, '용팔이': 200, '키': 201, '183인데': 202, '사람들끼리있을때': 203, '자기키': 204, '177이라하면': 205, '나는': 206, '어': 207, '내키는': 208, '175인데': 209, '해주면': 210, '주변사람들이': 211, '오오': 212, '너희': 213, '둘이': 214, '키재봐라': 215, '하는데': 216, '키재면': 217, '내가': 218, '더큼': 219, '슬퍼하는모습보는거': 220, '개꿀잼': 221, '이분': 222, '볼때마다': 223, '심장이': 224, '뭉클해지네': 225, '시위': 226, '진압': 227, 'ㅆㅅㅌㅊ였음': 228, '정재야': 229, '니': 230, '와그라노': 231, '뭔가': 232, '잘못이해한거같은데': 233, '문희상': 234, '천황드립이란': 235, '소린': 236, '문희상이': 237, '천황으로': 238, '말해서': 239, '잘못했다는게': 240, '아니라': 241, '애초에': 242, '일왕이라고': 243, '함': 244, '지금': 245, '천황이': 246, '전범': 247, '아들이니까': 248, '위안부에게': 249, '직접': 250, '사과시켜야한다는': 251, '불러올': 252, '파장을': 253, '생각도': 254, '못하고': 255, '경솔하게': 256, '대처해서': 257, '빌미를': 258, '줬다는': 259, '말이야': 260, '휴게소': 261, '마트': 262, '등의': 263, '여성전용주차장': 264, '보고': 265, '분노를': 266, '해야지': 267, '그런거야': 268, '영혼까지팔아도': 269, '된다는놈일거야': 270, '남친이노': 271, '진주네요': 272, '동네에': 273, '잠시': 274, '살았는데': 275, '주차': 276, '장난아닙니다': 277, '욕만': 278, '나오죠': 279, '피파': 280, '회장도': 281, '보냈잖아': 282, '우리나라였으면': 283, '남성1년': 284, '집해유예': 285, '엄마': 286, '20년': 287, '때릴것같네요': 288, '아님말구': 289, '가봤는데': 290, '11만원정도면': 291, '차라리': 292, '걍': 293, '호텔뷔페감호텔뷔페에': 294, '랍스터가없는것도': 295, '아니고': 296, '그냥그랫음': 297, '안동김씨': 298, '새로오면': 299, '그렇게함': 300, '열심히': 301, '하는티를': 302, '팍팍내고': 303, '바꾸고': 304, '뭐하기로': 305, '하자': 306, '압박을': 307, '주잖냐': 308, '10년간': 309, '타성에': 310, '젖어살았던거': 311, '아니냐': 312, '위기감없이': 313, '아부네': 314, '빌런vs빌런': 315, '저거': 316, '안비싸': 317, '수술도': 318, '남자': 319, '의사가': 320, '잘한다': 321, '그러나': 322, '그건': 323, '수치상일뿐': 324, '현실은': 325, '굉장히': 326, '망할': 327, '가능성이': 328, '높은': 329, '나라지': 330, '여자다': 331, '백종원': 332, '음식': 333, '자극적임': 334, '우스갯소리로': 335, '많이하던거니까': 336, '이만희총회장님께서': 337, '신천지구원으로': 338, '전세계에서': 339, '몰려': 340, '온다': 341, '하셨습니다': 342, '음': 343, '유튜브안하니': 344, '따라다니면서': 345, '교통법규위반': 346, '계속': 347, '신고할듯': 348, '야동도': 349, '교복입은건': 350, '안본다': 351, '에라이': 352, '띤도': 353, '최서현': 354, 'house': 355, 'party': 356, '추천': 357, '개띵곡': 358, '개우끼노ㅋㅋㅋㅋㅋㅋㅋㅋ': 359, '내말이': 360, '아직': 361, '세상물정을': 362, '잘': 363, '모르는것': 364, '같더라': 365, '사회생활이': 366, '적었나': 367, '다른': 368, '건': 369, '그런데': 370, '문씨거는': 371, '감동이다': 372, 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋ': 373, '뽑을': 374, '때': 375, '유도국대출신들': 376, '특채': 377, '있다': 378, '무도특채': 379, '그리고': 380, '들어가면': 381, '스스로': 382, '권투도장': 383, '다님': 384, '아참': 385, '레슬링선수출신': 386, '특채도': 387, '있었음': 388, '적당히를': 389, '넘어': 390, '꽐라될때까지': 391, '마셔서': 392, '문제지': 393, '새벽': 394, '2시': 395, '반에': 396, '고소장': 397, '제출이': 398, '가능한': 399, '나라가': 400, '세상에': 401, '어디있냐': 402, '창의력': 403, '인정': 404, '저': 405, '사건': 406, '판결문': 407, '찾아서': 408, '봐라': 409, '4': 410, '000만원': 411, '정도': 412, '지급': 413, '명령': 414, '받았음법원이': 415, '그렇게': 416, '판결': 417, '냈다는데': 418, '왜': 419, '아니라함': 420, '노동부': 421, '장관이라도': 422, '됨': 423, '프라이드': 424, '즐겨봤는데ㅋㅋ': 425, '사쿠라바': 426, '고미': 427, '다카노리': 428, '반달레이': 429, '실바': 430, '노게이라': 431, '개추억이네ㅋㅋㅋ': 432, '연말에': 433, '남제': 434, '이런거로': 435, '빅매치뜨고': 436, '대가들': 437, '굳이': 438, '한자까지': 439, '섞어서': 440, '글올리는이유가': 441, '머냐ㅋㅋㅋ': 442, '쪽도': 443, '매일': 444, '그러잖아요': 445, '공적': 446, '마스크': 447, '시행한다니까': 448, '사회주의': 449, '타령': 450, '심해공포증은없는데': 451, '우주공포증있음': 452, '짭ㅈㅎ주고싶다': 453, '서울은': 454, '조선족이': 455, '몰리는곳': 456, 'ㅇㅂ': 457, '화산지형이라': 458, '나쁘진': 459, '않을껄': 460, '강수량': 461, '많아서': 462, '물': 463, '좋음': 464, '2016년': 465, '12월': 466, '기사를': 467, '가져와서': 468, '올려놨으면': 469, '이후': 470, '어떻게': 471, '되었는지': 472, '설명이라도': 473, '좀': 474, '정신': 475, '못차렸네': 476, '굴다리밑': 477, '아들': 478, '국적이': 479, '할마시들이': 480, '가져가겠지': 481, 'ㄴㄴ': 482, '외모가': 483, '전부는': 484, '아니라고': 485, '생각함': 486, '필리핀은': 487, '경찰이': 488, '돈을': 489, '갈취함': 490, '10조쯤은': 491, '껌으로': 492, '땅사는': 493, '기업도': 494, '있는데': 495, '고참이': 496, '딸려들어간': 497, '스티로폼': 498, '씹을': 499, '때마다': 500, '희열을': 501, '느끼는': 502, '거야': 503, '연초밥': 504, '대하이햄만': 505, '찾으면': 506, '협상': 507, 'ok': 508, '누군들': 509, '중동여행': 510, '가보고싶지': 511, '않겠냐': 512, '직모는': 513, '답없다': 514, '무조건': 515, '스포츠짧은머리': 516, '모히칸': 517, '들어가야된다': 518, '번호판': 519, '세자리냐': 520, '거기에다': 521, '합성아니라고': 522, '했어': 523, '되냐': 524, '금발거유': 525, '무뇌': 526, '라는': 527, '스트레오타입': 528, '일단은': 529, '표현의': 530, '자유로': 531, '남겨놔야하는': 532, '것': 533, '같음': 534, '그럼': 535, '20분짜리영상': 536, '매일올리면': 537, '한달에': 538, '600임': 539, '그예로': 540, '벌써': 541, '중국이': 542, '마스크를': 543, '보내주었구요': 544}\n"
     ]
    }
   ],
   "source": [
    "sentences = df['Sentence'].tolist()\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : %d' % vocab_size)\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 개수 : 481\n",
      "[[26, 27], [26, 27, 28], [26, 27, 28, 29], [26, 27, 28, 29, 30], [26, 27, 28, 29, 30, 31], [26, 27, 28, 29, 30, 31, 32], [26, 27, 28, 29, 30, 31, 32, 33], [26, 27, 28, 29, 30, 31, 32, 33, 3], [34, 35], [34, 35, 36], [37, 38], [37, 38, 39], [37, 38, 39, 40], [37, 38, 39, 40, 41], [37, 38, 39, 40, 41, 42], [37, 38, 39, 40, 41, 42, 43], [37, 38, 39, 40, 41, 42, 43, 10], [37, 38, 39, 40, 41, 42, 43, 10, 44], [47, 48], [47, 48, 49], [47, 48, 49, 50], [47, 48, 49, 50, 51], [47, 48, 49, 50, 51, 52], [47, 48, 49, 50, 51, 52, 53], [54, 55], [54, 55, 56], [54, 55, 56, 57], [54, 55, 56, 57, 58], [54, 55, 56, 57, 58, 59], [54, 55, 56, 57, 58, 59, 60], [54, 55, 56, 57, 58, 59, 60, 61], [4, 1], [4, 1, 62], [4, 1, 62, 63], [64, 65], [64, 65, 66], [64, 65, 66, 67], [64, 65, 66, 67, 68], [64, 65, 66, 67, 68, 69], [64, 65, 66, 67, 68, 69, 70], [64, 65, 66, 67, 68, 69, 70, 71], [64, 65, 66, 67, 68, 69, 70, 71, 72], [64, 65, 66, 67, 68, 69, 70, 71, 72, 73], [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75], [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78], [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79], [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 11], [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 11, 81], [82, 83], [82, 83, 84], [82, 83, 84, 85], [86, 87], [86, 87, 88], [86, 87, 88, 89], [86, 87, 88, 89, 90], [86, 87, 88, 89, 90, 91], [86, 87, 88, 89, 90, 91, 92], [5, 93], [5, 93, 94], [5, 93, 94, 12], [5, 93, 94, 12, 13], [5, 93, 94, 12, 13, 1], [5, 93, 94, 12, 13, 1, 95], [5, 93, 94, 12, 13, 1, 95, 96], [5, 93, 94, 12, 13, 1, 95, 96, 97], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98, 12], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98, 12, 13], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98, 12, 13, 99], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98, 12, 13, 99, 15], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98, 12, 13, 99, 15, 1], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98, 12, 13, 99, 15, 1, 100], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98, 12, 13, 99, 15, 1, 100, 101], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98, 12, 13, 99, 15, 1, 100, 101, 102], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98, 12, 13, 99, 15, 1, 100, 101, 102, 14], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98, 12, 13, 99, 15, 1, 100, 101, 102, 14, 103], [5, 93, 94, 12, 13, 1, 95, 96, 97, 14, 98, 12, 13, 99, 15, 1, 100, 101, 102, 14, 103, 104], [3, 105], [3, 105, 106], [3, 105, 106, 107], [3, 105, 106, 107, 108], [3, 105, 106, 107, 108, 109], [3, 105, 106, 107, 108, 109, 110], [111, 112], [111, 112, 113], [111, 112, 113, 114], [111, 112, 113, 114, 115], [111, 112, 113, 114, 115, 116], [117, 118], [117, 118, 119], [121, 122], [121, 122, 123], [121, 122, 123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [131, 132, 133], [131, 132, 133, 134], [135, 136], [137, 138], [137, 138, 139], [137, 138, 139, 140], [137, 138, 139, 140, 141], [137, 138, 139, 140, 141, 142], [137, 138, 139, 140, 141, 142, 143], [137, 138, 139, 140, 141, 142, 143, 144], [137, 138, 139, 140, 141, 142, 143, 144, 145], [137, 138, 139, 140, 141, 142, 143, 144, 145, 146], [137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147], [137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148], [137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149], [6, 150], [151, 152], [151, 152, 153], [151, 152, 153, 154], [151, 152, 153, 154, 155], [151, 152, 153, 154, 155, 156], [151, 152, 153, 154, 155, 156, 157], [151, 152, 153, 154, 155, 156, 157, 158], [151, 152, 153, 154, 155, 156, 157, 158, 159], [151, 152, 153, 154, 155, 156, 157, 158, 159, 160], [151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161], [151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162], [151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163], [151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], [151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165], [151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166], [167, 168], [169, 170], [169, 170, 171], [169, 170, 171, 172], [169, 170, 171, 172, 173], [169, 170, 171, 172, 173, 174], [169, 170, 171, 172, 173, 174, 175], [2, 176], [177, 178], [177, 178, 179], [2, 180], [2, 180, 181], [2, 180, 181, 182], [2, 180, 181, 182, 183], [2, 180, 181, 182, 183, 184], [2, 180, 181, 182, 183, 184, 185], [2, 180, 181, 182, 183, 184, 185, 186], [2, 180, 181, 182, 183, 184, 185, 186, 187], [2, 180, 181, 182, 183, 184, 185, 186, 187, 188], [2, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189], [2, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190], [2, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191], [2, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192], [193, 194], [193, 194, 195], [196, 197], [198, 199], [7, 201], [7, 201, 202], [7, 201, 202, 203], [7, 201, 202, 203, 6], [7, 201, 202, 203, 6, 204], [7, 201, 202, 203, 6, 204, 205], [7, 201, 202, 203, 6, 204, 205, 206], [7, 201, 202, 203, 6, 204, 205, 206, 207], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211, 212], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 16], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 16, 220], [7, 201, 202, 203, 6, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 16, 220, 221], [8, 222], [8, 222, 223], [8, 222, 223, 224], [8, 222, 223, 224, 225], [9, 226], [9, 226, 227], [9, 226, 227, 228], [229, 230], [229, 230, 231], [232, 233], [232, 233, 234], [232, 233, 234, 235], [232, 233, 234, 235, 236], [232, 233, 234, 235, 236, 237], [232, 233, 234, 235, 236, 237, 238], [232, 233, 234, 235, 236, 237, 238, 239], [232, 233, 234, 235, 236, 237, 238, 239, 240], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 17], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 17, 252], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 17, 252, 253], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 17, 252, 253, 254], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 17, 252, 253, 254, 255], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 17, 252, 253, 254, 255, 256], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 17, 252, 253, 254, 255, 256, 257], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 17, 252, 253, 254, 255, 256, 257, 258], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 17, 252, 253, 254, 255, 256, 257, 258, 259], [232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 17, 252, 253, 254, 255, 256, 257, 258, 259, 260], [261, 262], [261, 262, 263], [261, 262, 263, 264], [261, 262, 263, 264, 265], [261, 262, 263, 264, 265, 266], [261, 262, 263, 264, 265, 266, 267], [8, 268], [8, 268, 16], [269, 270], [272, 18], [272, 18, 273], [272, 18, 273, 274], [272, 18, 273, 274, 275], [272, 18, 273, 274, 275, 18], [272, 18, 273, 274, 275, 18, 276], [272, 18, 273, 274, 275, 18, 276, 277], [272, 18, 273, 274, 275, 18, 276, 277, 2], [272, 18, 273, 274, 275, 18, 276, 277, 2, 278], [272, 18, 273, 274, 275, 18, 276, 277, 2, 278, 279], [280, 281], [280, 281, 282], [283, 284], [283, 284, 285], [283, 284, 285, 286], [283, 284, 285, 286, 287], [283, 284, 285, 286, 287, 288], [283, 284, 285, 286, 287, 288, 289], [290, 291], [290, 291, 292], [290, 291, 292, 293], [290, 291, 292, 293, 294], [290, 291, 292, 293, 294, 295], [290, 291, 292, 293, 294, 295, 296], [290, 291, 292, 293, 294, 295, 296, 297], [7, 298], [299, 1], [299, 1, 300], [299, 1, 300, 301], [299, 1, 300, 301, 302], [299, 1, 300, 301, 302, 303], [299, 1, 300, 301, 302, 303, 19], [299, 1, 300, 301, 302, 303, 19, 304], [299, 1, 300, 301, 302, 303, 19, 304, 305], [299, 1, 300, 301, 302, 303, 19, 304, 305, 306], [299, 1, 300, 301, 302, 303, 19, 304, 305, 306, 307], [299, 1, 300, 301, 302, 303, 19, 304, 305, 306, 307, 308], [299, 1, 300, 301, 302, 303, 19, 304, 305, 306, 307, 308, 309], [299, 1, 300, 301, 302, 303, 19, 304, 305, 306, 307, 308, 309, 20], [299, 1, 300, 301, 302, 303, 19, 304, 305, 306, 307, 308, 309, 20, 310], [299, 1, 300, 301, 302, 303, 19, 304, 305, 306, 307, 308, 309, 20, 310, 311], [299, 1, 300, 301, 302, 303, 19, 304, 305, 306, 307, 308, 309, 20, 310, 311, 312], [299, 1, 300, 301, 302, 303, 19, 304, 305, 306, 307, 308, 309, 20, 310, 311, 312, 313], [21, 21], [21, 21, 314], [316, 317], [318, 319], [318, 319, 320], [318, 319, 320, 321], [322, 323], [322, 323, 324], [322, 323, 324, 325], [322, 323, 324, 325, 326], [322, 323, 324, 325, 326, 327], [322, 323, 324, 325, 326, 327, 328], [322, 323, 324, 325, 326, 327, 328, 329], [322, 323, 324, 325, 326, 327, 328, 329, 330], [4, 331], [332, 333], [332, 333, 20], [332, 333, 20, 334], [335, 336], [337, 338], [337, 338, 339], [337, 338, 339, 340], [337, 338, 339, 340, 341], [337, 338, 339, 340, 341, 342], [343, 344], [6, 345], [6, 345, 346], [6, 345, 346, 347], [6, 345, 346, 347, 348], [5, 349], [5, 349, 350], [5, 349, 350, 351], [5, 349, 350, 351, 352], [353, 354], [353, 354, 355], [353, 354, 355, 356], [353, 354, 355, 356, 357], [353, 354, 355, 356, 357, 358], [360, 3], [360, 3, 361], [360, 3, 361, 362], [360, 3, 361, 362, 363], [360, 3, 361, 362, 363, 364], [360, 3, 361, 362, 363, 364, 365], [360, 3, 361, 362, 363, 364, 365, 366], [360, 3, 361, 362, 363, 364, 365, 366, 367], [368, 369], [368, 369, 370], [368, 369, 370, 371], [368, 369, 370, 371, 372], [373, 9], [22, 374], [22, 374, 375], [22, 374, 375, 376], [22, 374, 375, 376, 377], [22, 374, 375, 376, 377, 378], [22, 374, 375, 376, 377, 378, 379], [22, 374, 375, 376, 377, 378, 379, 380], [22, 374, 375, 376, 377, 378, 379, 380, 22], [22, 374, 375, 376, 377, 378, 379, 380, 22, 381], [22, 374, 375, 376, 377, 378, 379, 380, 22, 381, 382], [22, 374, 375, 376, 377, 378, 379, 380, 22, 381, 382, 383], [22, 374, 375, 376, 377, 378, 379, 380, 22, 381, 382, 383, 384], [22, 374, 375, 376, 377, 378, 379, 380, 22, 381, 382, 383, 384, 385], [22, 374, 375, 376, 377, 378, 379, 380, 22, 381, 382, 383, 384, 385, 386], [22, 374, 375, 376, 377, 378, 379, 380, 22, 381, 382, 383, 384, 385, 386, 387], [22, 374, 375, 376, 377, 378, 379, 380, 22, 381, 382, 383, 384, 385, 386, 387, 388], [389, 390], [389, 390, 391], [389, 390, 391, 392], [389, 390, 391, 392, 393], [394, 395], [394, 395, 396], [394, 395, 396, 397], [394, 395, 396, 397, 398], [394, 395, 396, 397, 398, 399], [394, 395, 396, 397, 398, 399, 400], [394, 395, 396, 397, 398, 399, 400, 401], [394, 395, 396, 397, 398, 399, 400, 401, 402], [403, 404], [405, 406], [405, 406, 407], [405, 406, 407, 408], [405, 406, 407, 408, 409], [405, 406, 407, 408, 409, 410], [405, 406, 407, 408, 409, 410, 411], [405, 406, 407, 408, 409, 410, 411, 412], [405, 406, 407, 408, 409, 410, 411, 412, 413], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 23], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 23, 420], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 23, 420, 23], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 23, 420, 23, 421], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 23, 420, 23, 421, 422], [405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 23, 420, 23, 421, 422, 423], [5, 424], [5, 424, 425], [5, 424, 425, 426], [5, 424, 425, 426, 427], [5, 424, 425, 426, 427, 428], [5, 424, 425, 426, 427, 428, 429], [5, 424, 425, 426, 427, 428, 429, 430], [5, 424, 425, 426, 427, 428, 429, 430, 431], [5, 424, 425, 426, 427, 428, 429, 430, 431, 15], [5, 424, 425, 426, 427, 428, 429, 430, 431, 15, 432], [5, 424, 425, 426, 427, 428, 429, 430, 431, 15, 432, 433], [5, 424, 425, 426, 427, 428, 429, 430, 431, 15, 432, 433, 434], [5, 424, 425, 426, 427, 428, 429, 430, 431, 15, 432, 433, 434, 435], [5, 424, 425, 426, 427, 428, 429, 430, 431, 15, 432, 433, 434, 435, 436], [438, 439], [438, 439, 440], [438, 439, 440, 441], [438, 439, 440, 441, 442], [24, 443], [24, 443, 444], [24, 443, 444, 445], [24, 443, 444, 445, 446], [24, 443, 444, 445, 446, 447], [24, 443, 444, 445, 446, 447, 448], [24, 443, 444, 445, 446, 447, 448, 10], [24, 443, 444, 445, 446, 447, 448, 10, 449], [24, 443, 444, 445, 446, 447, 448, 10, 449, 450], [451, 452], [8, 453], [454, 455], [454, 455, 456], [9, 457], [458, 459], [458, 459, 460], [458, 459, 460, 461], [458, 459, 460, 461, 462], [458, 459, 460, 461, 462, 463], [458, 459, 460, 461, 462, 463, 464], [465, 466], [465, 466, 467], [465, 466, 467, 468], [465, 466, 467, 468, 469], [465, 466, 467, 468, 469, 24], [465, 466, 467, 468, 469, 24, 470], [465, 466, 467, 468, 469, 24, 470, 471], [465, 466, 467, 468, 469, 24, 470, 471, 472], [465, 466, 467, 468, 469, 24, 470, 471, 472, 473], [465, 466, 467, 468, 469, 24, 470, 471, 472, 473, 474], [475, 476], [477, 478], [477, 478, 479], [477, 478, 479, 25], [480, 481], [482, 483], [482, 483, 484], [482, 483, 484, 485], [482, 483, 484, 485, 486], [487, 11], [487, 11, 488], [487, 11, 488, 489], [487, 11, 488, 489, 490], [487, 11, 488, 489, 490, 25], [19, 491], [19, 491, 492], [19, 491, 492, 493], [19, 491, 492, 493, 494], [19, 491, 492, 493, 494, 495], [496, 497], [496, 497, 498], [496, 497, 498, 499], [496, 497, 498, 499, 500], [496, 497, 498, 499, 500, 501], [496, 497, 498, 499, 500, 501, 502], [496, 497, 498, 499, 500, 501, 502, 503], [505, 506], [505, 506, 507], [505, 506, 507, 508], [509, 510], [509, 510, 511], [509, 510, 511, 512], [513, 514], [513, 514, 2], [513, 514, 2, 515], [513, 514, 2, 515, 516], [513, 514, 2, 515, 516, 517], [513, 514, 2, 515, 516, 517, 518], [519, 520], [7, 521], [7, 521, 522], [7, 521, 522, 523], [4, 17], [4, 17, 524], [525, 526], [525, 526, 527], [525, 526, 527, 528], [529, 530], [529, 530, 531], [529, 530, 531, 532], [529, 530, 531, 532, 533], [529, 530, 531, 532, 533, 534], [535, 536], [535, 536, 537], [535, 536, 537, 538], [535, 536, 537, 538, 539], [540, 541], [540, 541, 542], [540, 541, 542, 543], [540, 541, 542, 543, 544]]\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for line in sentences:\n",
    "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[: i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "print('학습에 사용할 샘플의 개수 : %d' % len(sequences))\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 30\n",
      "[[  0   0   0 ...   0  26  27]\n",
      " [  0   0   0 ...  26  27  28]\n",
      " [  0   0   0 ...  27  28  29]\n",
      " ...\n",
      " [  0   0   0 ... 540 541 542]\n",
      " [  0   0   0 ... 541 542 543]\n",
      " [  0   0   0 ... 542 543 544]]\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences) # 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
    "print('샘플의 최대 길이 : {}'.format(max_len))\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481, 30)\n"
     ]
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]\n",
    "\n",
    "print(sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0   0  26]\n",
      " [  0   0   0 ...   0  26  27]\n",
      " [  0   0   0 ...  26  27  28]\n",
      " ...\n",
      " [  0   0   0 ...   0 540 541]\n",
      " [  0   0   0 ... 540 541 542]\n",
      " [  0   0   0 ... 541 542 543]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27  28  29  30  31  32  33   3  35  36  38  39  40  41  42  43  10  44\n",
      "  48  49  50  51  52  53  55  56  57  58  59  60  61   1  62  63  65  66\n",
      "  67  68  69  70  71  72  73  74  75  76  77  78  79  80  11  81  83  84\n",
      "  85  87  88  89  90  91  92  93  94  12  13   1  95  96  97  14  98  12\n",
      "  13  99  15   1 100 101 102  14 103 104 105 106 107 108 109 110 112 113\n",
      " 114 115 116 118 119 122 123 124 126 128 130 132 133 134 136 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149 150 152 153 154 155 156 157 158 159\n",
      " 160 161 162 163 164 165 166 168 170 171 172 173 174 175 176 178 179 180\n",
      " 181 182 183 184 185 186 187 188 189 190 191 192 194 195 197 199 201 202\n",
      " 203   6 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219\n",
      "  16 220 221 222 223 224 225 226 227 228 230 231 233 234 235 236 237 238\n",
      " 239 240 241 242 243 244 245 246 247 248 249 250 251  17 252 253 254 255\n",
      " 256 257 258 259 260 262 263 264 265 266 267 268  16 270  18 273 274 275\n",
      "  18 276 277   2 278 279 281 282 284 285 286 287 288 289 291 292 293 294\n",
      " 295 296 297 298   1 300 301 302 303  19 304 305 306 307 308 309  20 310\n",
      " 311 312 313  21 314 317 319 320 321 323 324 325 326 327 328 329 330 331\n",
      " 333  20 334 336 338 339 340 341 342 344 345 346 347 348 349 350 351 352\n",
      " 354 355 356 357 358   3 361 362 363 364 365 366 367 369 370 371 372   9\n",
      " 374 375 376 377 378 379 380  22 381 382 383 384 385 386 387 388 390 391\n",
      " 392 393 395 396 397 398 399 400 401 402 404 406 407 408 409 410 411 412\n",
      " 413 414 415 416 417 418 419  23 420  23 421 422 423 424 425 426 427 428\n",
      " 429 430 431  15 432 433 434 435 436 439 440 441 442 443 444 445 446 447\n",
      " 448  10 449 450 452 453 455 456 457 459 460 461 462 463 464 466 467 468\n",
      " 469  24 470 471 472 473 474 476 478 479  25 481 483 484 485 486  11 488\n",
      " 489 490  25 491 492 493 494 495 497 498 499 500 501 502 503 506 507 508\n",
      " 510 511 512 514   2 515 516 517 518 520 521 522 523  17 524 526 527 528\n",
      " 530 531 532 533 534 536 537 538 539 541 542 543 544]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 모델 설계하기\n",
    "RNN 모델에 데이터를 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 10\n",
    "hidden_units = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_1/simple_rnn_1/while/simple_rnn_cell_1/MatMul_1' defined at (most recent call last):\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\GJAISCHOOL\\AppData\\Local\\Temp\\ipykernel_9664\\827228583.py\", line 1, in <module>\n      model.fit(X, y, epochs=200, verbose=2)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 515, in __call__\n      return super(RNN, self).__call__(inputs, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\simple_rnn.py\", line 391, in call\n      return super(SimpleRNN, self).call(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 652, in call\n      last_output, outputs, states = backend.rnn(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\backend.py\", line 4776, in rnn\n      final_outputs = tf.compat.v1.while_loop(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\backend.py\", line 4759, in _step\n      output, new_states = step_function(current_input,\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 648, in step\n      output, new_states = cell_call_fn(inputs, states, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\simple_rnn.py\", line 194, in call\n      output = h + backend.dot(prev_output, self.recurrent_kernel)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\backend.py\", line 2223, in dot\n      out = tf.matmul(x, y)\nNode: 'sequential_1/simple_rnn_1/while/simple_rnn_cell_1/MatMul_1'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node sequential_1/simple_rnn_1/while/simple_rnn_cell_1/MatMul_1}}]] [Op:__inference_train_function_3023]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\Algorithm\\RNN\\RNN_2.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/GJAISCHOOL/Desktop/X_filter/Algorithm/RNN/RNN_2.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X, y, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_1/simple_rnn_1/while/simple_rnn_cell_1/MatMul_1' defined at (most recent call last):\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\GJAISCHOOL\\AppData\\Local\\Temp\\ipykernel_9664\\827228583.py\", line 1, in <module>\n      model.fit(X, y, epochs=200, verbose=2)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 515, in __call__\n      return super(RNN, self).__call__(inputs, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\simple_rnn.py\", line 391, in call\n      return super(SimpleRNN, self).call(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 652, in call\n      last_output, outputs, states = backend.rnn(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\backend.py\", line 4776, in rnn\n      final_outputs = tf.compat.v1.while_loop(\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\backend.py\", line 4759, in _step\n      output, new_states = step_function(current_input,\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 648, in step\n      output, new_states = cell_call_fn(inputs, states, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\layers\\rnn\\simple_rnn.py\", line 194, in call\n      output = h + backend.dot(prev_output, self.recurrent_kernel)\n    File \"c:\\Users\\GJAISCHOOL\\.conda\\envs\\nv38\\lib\\site-packages\\keras\\backend.py\", line 2223, in dot\n      out = tf.matmul(x, y)\nNode: 'sequential_1/simple_rnn_1/while/simple_rnn_cell_1/MatMul_1'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node sequential_1/simple_rnn_1/while/simple_rnn_cell_1/MatMul_1}}]] [Op:__inference_train_function_3023]"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word\n",
    "    sentence  = ''\n",
    "\n",
    "    # n번 반복\n",
    "    for _ in range(n):\n",
    "        # 현재 단어에 대한 정수 인코딩과 패딩\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "        # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
    "            if index == result:\n",
    "                break\n",
    "\n",
    "        # 현재 단어 + ' ' + dPcmr eksdjfmf guswo eksdjfh qusrud\n",
    "        current_word = current_word + ' ' + word\n",
    "        \n",
    "        # 예측 단어를 문장에 저장\n",
    "        sentence = sentence + ' ' + word\n",
    "    \n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence_generation(model, tokenizer, '사랑해', 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
