{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=43126452224)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16915277672148090415\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 83126452224\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4784665803931406646\n",
      "physical_device_desc: \"device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:00:05.0, compute capability: 9.0\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21839, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 경로\n",
    "csv_path = r'C:\\Users\\administrator\\Desktop\\X_filter\\AI_Model\\dataset\\rnn_sentence_data(완성).csv'\n",
    "\n",
    "# CSV 파일 읽어오기\n",
    "LSTM_df = pd.read_csv(csv_path)\n",
    "\n",
    "# LSTM_df = LSTM_df[:50]\n",
    "# 데이터 확인\n",
    "print(LSTM_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst =[]\n",
    "for i in range(21800):\n",
    "    lst.append(i)\n",
    "\n",
    "LSTM_df.drop(index=lst,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 데이터 추출\n",
    "text = ' '.join(LSTM_df['Sentence'].astype(str))\n",
    "\n",
    "# 고유한 단어 목록 생성\n",
    "words = sorted(list(set(text.split())))\n",
    "\n",
    "# 단어와 인덱스 매핑 생성\n",
    "word_to_index = {word: index for index, word in enumerate(words)}\n",
    "index_to_word = {index: word for index, word in enumerate(words)}\n",
    "\n",
    "# 텍스트를 단어 인덱스로 변환\n",
    "text_as_int = np.array([word_to_index[word] for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 입력 시퀀스와 타겟 시퀀스 생성\n",
    "seq_length = 30 # 30\n",
    "examples_per_epoch = len(text.split()) // (seq_length + 1)\n",
    "\n",
    "word_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "LSTM_sequences = word_dataset.batch(seq_length + 1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "LSTM_model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/dense/Tensordot/MatMul' defined at (most recent call last):\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\traitlets\\config\\application.py\", line 1077, in launch_instance\n      app.start()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 529, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 518, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 424, in dispatch_shell\n      await result\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 766, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\administrator\\AppData\\Local\\Temp\\2\\ipykernel_5344\\3560277416.py\", line 5, in <module>\n      LSTM_model.fit(np.expand_dims(input_text, 0), np.expand_dims(target_text, 0), epochs=1, batch_size=1, verbose=2)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 244, in call\n      outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\nNode: 'sequential/dense/Tensordot/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node sequential/dense/Tensordot/MatMul}}]] [Op:__inference_train_function_2647]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\administrator\\Desktop\\X_filter\\AI_Model\\LSTM.ipynb 셀 12\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/administrator/Desktop/X_filter/AI_Model/LSTM.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/administrator/Desktop/X_filter/AI_Model/LSTM.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m input_text, target_text \u001b[39min\u001b[39;00m LSTM_dataset:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/administrator/Desktop/X_filter/AI_Model/LSTM.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         LSTM_model\u001b[39m.\u001b[39;49mfit(np\u001b[39m.\u001b[39;49mexpand_dims(input_text, \u001b[39m0\u001b[39;49m), np\u001b[39m.\u001b[39;49mexpand_dims(target_text, \u001b[39m0\u001b[39;49m), epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/administrator/Desktop/X_filter/AI_Model/LSTM.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         LSTM_model\u001b[39m.\u001b[39mreset_states()\n",
      "File \u001b[1;32mc:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/dense/Tensordot/MatMul' defined at (most recent call last):\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\traitlets\\config\\application.py\", line 1077, in launch_instance\n      app.start()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\asyncio\\base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\asyncio\\base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 529, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 518, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 424, in dispatch_shell\n      await result\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 766, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\administrator\\AppData\\Local\\Temp\\2\\ipykernel_5344\\3560277416.py\", line 5, in <module>\n      LSTM_model.fit(np.expand_dims(input_text, 0), np.expand_dims(target_text, 0), epochs=1, batch_size=1, verbose=2)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\administrator\\anaconda3\\envs\\TM\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 244, in call\n      outputs = tf.tensordot(inputs, self.kernel, [[rank - 1], [0]])\nNode: 'sequential/dense/Tensordot/MatMul'\nAttempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[{{node sequential/dense/Tensordot/MatMul}}]] [Op:__inference_train_function_2647]"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    for input_text, target_text in LSTM_dataset:\n",
    "        LSTM_model.fit(np.expand_dims(input_text, 0), np.expand_dims(target_text, 0), epochs=1, batch_size=1, verbose=2)\n",
    "        LSTM_model.reset_states()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y 생성\n",
    "LSTM_X = []\n",
    "LSTM_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_text, target_text in LSTM_dataset:\n",
    "    LSTM_X.append(input_text.numpy())\n",
    "    LSTM_y.append(target_text.numpy())\n",
    "\n",
    "LSTM_X = np.array(LSTM_X)\n",
    "LSTM_y = np.array(LSTM_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메트릭 평가\n",
    "def evaluate_metrics(LSTM_model, LSTM_X, LSTM_y):\n",
    "    total_samples = LSTM_X.shape[0]\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "\n",
    "    for i in range(total_samples):\n",
    "        X_sample = LSTM_X[i, :]\n",
    "        y_true = np.argmax(LSTM_y[i])\n",
    "\n",
    "        # 모델을 사용하여 다음 단어 예측\n",
    "        y_pred_probs = LSTM_model.predict(X_sample.reshape(1, -1), verbose=0)\n",
    "        y_pred = np.argmax(y_pred_probs)\n",
    "\n",
    "        y_true_all.append(y_true)\n",
    "        y_pred_all.append(y_pred)\n",
    "\n",
    "    # 정확도 계산\n",
    "    accuracy = accuracy_score(y_true_all, y_pred_all)\n",
    "\n",
    "    # 재현율 계산\n",
    "    recall = recall_score(y_true_all, y_pred_all, average='weighted')\n",
    "\n",
    "    # 정밀도 계산\n",
    "    precision = precision_score(y_true_all, y_pred_all, average='weighted')\n",
    "\n",
    "    # F1 점수 계산\n",
    "    f1 = f1_score(y_true_all, y_pred_all, average='weighted')\n",
    "\n",
    "    return accuracy, recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메트릭 평가\n",
    "accuracy, recall, precision, f1 = evaluate_metrics(LSTM_model, LSTM_X, LSTM_y)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'다음 단어 예측 정확도: {accuracy}')\n",
    "print(f'다음 단어 예측 재현율: {recall}')\n",
    "print(f'다음 단어 예측 정밀도: {precision}')\n",
    "print(f'다음 단어 예측 F1 점수: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(start_word, model, max_length=50):\n",
    "    # 시작 단어를 토큰화합니다.\n",
    "    input_sequence = [word_to_index[start_word]]  # 수정: 변수명을 맞춤\n",
    "\n",
    "    # 최대 길이에 도달하거나 종료 토큰을 만날 때까지 텍스트를 생성합니다.\n",
    "    for _ in range(max_length):\n",
    "        # 입력 시퀀스를 훈련 데이터와 동일한 길이로 패딩합니다.\n",
    "        pad_sequences = pad_sequences([input_sequence], maxlen=seq_length, padding='pre')  # 수정: max_sequence_length -> seq_length\n",
    "\n",
    "        # 모델을 사용하여 다음 단어를 예측합니다.\n",
    "        predictions = model.predict(pad_sequences)\n",
    "        predicted_index = np.argmax(predictions)\n",
    "\n",
    "        # 예측된 인덱스를 다시 단어로 변환합니다.\n",
    "        predicted_word = index_to_word[predicted_index]  # 수정: reverse_word_index -> index_to_word\n",
    "\n",
    "        # 종료 토큰이 예측되면 중단합니다.\n",
    "        if predicted_word == '<END_TOKEN>':\n",
    "            break\n",
    "\n",
    "        # 예측된 단어를 다음 반복을 위해 입력 시퀀스에 추가합니다.\n",
    "        input_sequence.append(predicted_index)\n",
    "\n",
    "    # 생성된 시퀀스를 다시 텍스트 문자열로 변환합니다.\n",
    "    generated_text = ' '.join([index_to_word[idx] for idx in input_sequence])  # 수정: reverse_word_index -> index_to_word\n",
    "\n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# nltk를 사용하기 전에 필요한 리소스 다운로드\n",
    "nltk.download('punkt')\n",
    "\n",
    "def generate_and_find_best_bleu_score(start_word, num_generate=2, temperature=1.0):\n",
    "    reference_sentences = LSTM_df['Sentence'].tolist()\n",
    "    best_sentence = None\n",
    "    best_bleu_score = 0.0\n",
    "\n",
    "    for _ in range(num_generate):\n",
    "        # 생성된 문장\n",
    "        generated_sentence = generate_text(start_word, LSTM_model, max_length=50)  # 수정: generate_text 함수 호출 시 올바른 인수 전달\n",
    "\n",
    "\n",
    "        # 각 참조 문장과의 블루스코어 계산\n",
    "        bleu_scores = []\n",
    "        for reference_sentence in reference_sentences:\n",
    "            reference = nltk.word_tokenize(reference_sentence.lower())\n",
    "            generated = nltk.word_tokenize(generated_sentence.lower())\n",
    "            bleu_score = sentence_bleu([reference], generated, weights=(1, 0, 0, 0))  # 1-gram만 고려\n",
    "            bleu_scores.append(bleu_score)\n",
    "\n",
    "        # 참조 문장들과의 평균 블루스코어 계산\n",
    "        average_bleu_score = np.mean(bleu_scores)\n",
    "\n",
    "        # 가장 높은 블루스코어를 가진 문장을 저장\n",
    "        if average_bleu_score > best_bleu_score:\n",
    "            best_bleu_score = average_bleu_score\n",
    "            best_sentence = generated_sentence\n",
    "\n",
    "    return best_sentence, best_bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_find_best_bleu_score(\"저런\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_and_find_best_bleu_score('이런'))\n",
    "print(generate_and_find_best_bleu_score('진짜'))\n",
    "print(generate_and_find_best_bleu_score('바보'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_excel(r'C:\\Users\\administrator\\Desktop\\X_filter\\AI_Model\\dataset\\word_list ().xlsx')\n",
    "for word in word_df['대체어_중복']:\n",
    "    LSTM_text = generate_and_find_best_bleu_score(word, 4)\n",
    "    print(LSTM_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# # CSV 파일 경로\n",
    "# csv_path = r'C:\\Users\\GJAISCHOOL\\Desktop\\X_filter\\AI_Model\\dataset\\rnn_sentence_data(완성).csv'\n",
    "\n",
    "# # CSV 파일 읽어오기\n",
    "# df = pd.read_csv(csv_path)\n",
    "\n",
    "# df = df[:50]\n",
    "# # 데이터 확인\n",
    "# print(df.shape)\n",
    "\n",
    "# # 텍스트 데이터 추출\n",
    "# text = ' '.join(df['Sentence'].astype(str))\n",
    "\n",
    "# # 고유한 단어 목록 생성\n",
    "# words = sorted(list(set(text.split())))\n",
    "\n",
    "# # 단어와 인덱스 매핑 생성\n",
    "# word_to_index = {word: index for index, word in enumerate(words)}\n",
    "# index_to_word = {index: word for index, word in enumerate(words)}\n",
    "\n",
    "# # 텍스트를 단어 인덱스로 변환\n",
    "# text_as_int = np.array([word_to_index[word] for word in text.split()])\n",
    "\n",
    "# # 입력 시퀀스와 타겟 시퀀스 생성\n",
    "# seq_length = 30\n",
    "# examples_per_epoch = len(text.split()) // (seq_length + 1)\n",
    "\n",
    "# word_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "# sequences = word_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "# def split_input_target(chunk):\n",
    "#     input_text = chunk[:-1]\n",
    "#     target_text = chunk[1:]\n",
    "#     return input_text, target_text\n",
    "\n",
    "# dataset = sequences.map(split_input_target)\n",
    "\n",
    "# # 모델 구축\n",
    "# vocab_size = len(words)\n",
    "# embedding_dim = 256\n",
    "# rnn_units = 1024\n",
    "\n",
    "# model = Sequential([\n",
    "#     Embedding(vocab_size, embedding_dim, input_length=seq_length, batch_input_shape=[1, None]),\n",
    "#     LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform', batch_input_shape=[1, None, embedding_dim]),\n",
    "#     Dense(vocab_size)\n",
    "# ])\n",
    "\n",
    "# # 모델 컴파일\n",
    "# model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "# # 모델 훈련\n",
    "# epochs = 50\n",
    "# for epoch in range(epochs):\n",
    "#     for input_text, target_text in dataset:\n",
    "#         model.fit(np.expand_dims(input_text, 0), np.expand_dims(target_text, 0), epochs=1, batch_size=1, verbose=2)\n",
    "#         model.reset_states()\n",
    "\n",
    "# # X, y 생성\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# for input_text, target_text in dataset:\n",
    "#     X.append(input_text.numpy())\n",
    "#     y.append(target_text.numpy())\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# # 메트릭 평가\n",
    "# def evaluate_metrics(model, X, y):\n",
    "#     total_samples = X.shape[0]\n",
    "#     y_true_all = []\n",
    "#     y_pred_all = []\n",
    "\n",
    "#     for i in range(total_samples):\n",
    "#         X_sample = X[i, :]\n",
    "#         y_true = np.argmax(y[i])\n",
    "\n",
    "#         # 모델을 사용하여 다음 단어 예측\n",
    "#         y_pred_probs = model.predict(X_sample.reshape(1, -1), verbose=0)\n",
    "#         y_pred = np.argmax(y_pred_probs)\n",
    "\n",
    "#         y_true_all.append(y_true)\n",
    "#         y_pred_all.append(y_pred)\n",
    "\n",
    "#     # 정확도 계산\n",
    "#     accuracy = accuracy_score(y_true_all, y_pred_all)\n",
    "\n",
    "#     # 재현율 계산\n",
    "#     recall = recall_score(y_true_all, y_pred_all, average='weighted')\n",
    "\n",
    "#     # 정밀도 계산\n",
    "#     precision = precision_score(y_true_all, y_pred_all, average='weighted')\n",
    "\n",
    "#     # F1 점수 계산\n",
    "#     f1 = f1_score(y_true_all, y_pred_all, average='weighted')\n",
    "\n",
    "#     return accuracy, recall, precision, f1\n",
    "\n",
    "# # 메트릭 평가\n",
    "# accuracy, recall, precision, f1 = evaluate_metrics(model, X, y)\n",
    "\n",
    "# # 결과 출력\n",
    "# print(f'다음 단어 예측 정확도: {accuracy}')\n",
    "# print(f'다음 단어 예측 재현율: {recall}')\n",
    "# print(f'다음 단어 예측 정밀도: {precision}')\n",
    "# print(f'다음 단어 예측 F1 점수: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
